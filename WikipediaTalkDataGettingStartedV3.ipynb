{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Talk Data - Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file contains the experiments performed and the accuracy of each. The best performing ones were selected and used in the a different file for submission purposes. \n",
    "\n",
    "### - Surya Roshan M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an introduction to working with the various data sets in [Wikipedia\n",
    "Talk](https://figshare.com/projects/Wikipedia_Talk/16731) project on Figshare. The release includes:\n",
    "\n",
    "1. a large historical corpus of discussion comments on Wikipedia talk pages\n",
    "2. a sample of over 100k comments with human labels for whether the comment contains a personal attack\n",
    "3. a sample of over 100k comments with human labels for whether the comment has aggressive tone\n",
    "\n",
    "Please refer to our [wiki](https://meta.wikimedia.org/wiki/Research:Detox/Data_Release) for documentation of the schema of each data set and our [research paper](https://arxiv.org/abs/1610.08914) for documentation on the data collection and modeling methodology. \n",
    "\n",
    "In this notebook we show how to build a simple classifier for detecting personal attacks and apply the classifier to a random sample of the comment corpus to see whether discussions on user pages have more personal attacks than discussion on article pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building a classifier for personal attacks\n",
    "In this section we will train a simple bag-of-words classifier for personal attacks using the [Wikipedia Talk Labels: Personal Attacks]() data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#\"import pandas_profiling as pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "# You can edit the code here to download only once, and not download it later                \n",
    "#download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "#download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use display instead of Print to print prettily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185345</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN::Thanks. While I'm ...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212997</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220372</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENWikipedia is banned?...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221055</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN::I've been conside...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226695</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...</td>\n",
       "      <td>2003</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  year  logged_in  \\\n",
       "rev_id                                                                        \n",
       "37675    `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "44816    `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "49851    NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
       "89320     Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                 This page will need disambiguation.   2002       True   \n",
       "...                                                    ...   ...        ...   \n",
       "1185345  NEWLINE_TOKENNEWLINE_TOKEN::Thanks. While I'm ...  2003       True   \n",
       "1212997  NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...  2003       True   \n",
       "1220372  NEWLINE_TOKENNEWLINE_TOKENWikipedia is banned?...  2003       True   \n",
       "1221055  `NEWLINE_TOKENNEWLINE_TOKEN::I've been conside...  2003       True   \n",
       "1226695  NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...  2003      False   \n",
       "\n",
       "              ns  sample  split  \n",
       "rev_id                           \n",
       "37675    article  random  train  \n",
       "44816    article  random  train  \n",
       "49851    article  random  train  \n",
       "89320    article  random    dev  \n",
       "93890    article  random  train  \n",
       "...          ...     ...    ...  \n",
       "1185345  article  random   test  \n",
       "1212997     user  random    dev  \n",
       "1220372  article  random   test  \n",
       "1221055  article  random   test  \n",
       "1226695     user  random    dev  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(annotations.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annotators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "37675   `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
       "89320    Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                This page will need disambiguation.   2002       True   \n",
       "\n",
       "             ns  sample  split  attack  \n",
       "rev_id                                  \n",
       "37675   article  random  train   False  \n",
       "44816   article  random  train   False  \n",
       "49851   article  random  train   False  \n",
       "89320   article  random    dev   False  \n",
       "93890   article  random  train   False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels\n",
    "display(comments.head())\n",
    "comments.to_csv(\"raw_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3296/4056290540.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'comments' is not defined"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['comment']=comments['comment'].apply(lambda x: x.replace(\"`\",\" \"))\n",
    "comments['comment']=comments['comment'].apply(lambda x: x.replace(\".\",\" \"))\n",
    "#comments['comment']=comments['comment'].apply(lambda x: x.lower())\n",
    "import re\n",
    "comments['comment']=comments['comment'].apply(lambda x: re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', x))\n",
    "comments['comment']=comments['comment'].apply(lambda s : re.sub(r'[^\\w\\s]','',s))\n",
    "comments['comment']=comments['comment'].apply(lambda x:  re.sub(\"\\S*\\d\\S*\", \"\", x).strip())\n",
    "\n",
    "comments['comment']=comments['comment'].apply(lambda x: re.sub(r'\\s+',\" \",x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This contains the full data which can be used for training or other purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>This is not creative Those are the dictionary ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less NPOV th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>True or false the situation as of March was su...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next maybe you could work on being less condes...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185345</th>\n",
       "      <td>Thanks While Im attemtping without any trainin...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212997</th>\n",
       "      <td>Hi Sannse I answered you question on the talkW...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220372</th>\n",
       "      <td>Wikipedia is banned Why</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221055</th>\n",
       "      <td>Ive been considering the proposed version whic...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226695</th>\n",
       "      <td>Do you think European Union should have the fo...</td>\n",
       "      <td>2003</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  year  logged_in  \\\n",
       "rev_id                                                                        \n",
       "37675    This is not creative Those are the dictionary ...  2002      False   \n",
       "44816    the term standard model is itself less NPOV th...  2002      False   \n",
       "49851    True or false the situation as of March was su...  2002      False   \n",
       "89320    Next maybe you could work on being less condes...  2002       True   \n",
       "93890                   This page will need disambiguation  2002       True   \n",
       "...                                                    ...   ...        ...   \n",
       "1185345  Thanks While Im attemtping without any trainin...  2003       True   \n",
       "1212997  Hi Sannse I answered you question on the talkW...  2003       True   \n",
       "1220372                            Wikipedia is banned Why  2003       True   \n",
       "1221055  Ive been considering the proposed version whic...  2003       True   \n",
       "1226695  Do you think European Union should have the fo...  2003      False   \n",
       "\n",
       "              ns  sample  split  attack  \n",
       "rev_id                                   \n",
       "37675    article  random  train   False  \n",
       "44816    article  random  train   False  \n",
       "49851    article  random  train   False  \n",
       "89320    article  random    dev   False  \n",
       "93890    article  random  train   False  \n",
       "...          ...     ...    ...     ...  \n",
       "1185345  article  random   test   False  \n",
       "1212997     user  random    dev   False  \n",
       "1220372  article  random   test   False  \n",
       "1221055  article  random   test   False  \n",
       "1226695     user  random    dev   False  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment      object\n",
       "year          int64\n",
       "logged_in      bool\n",
       "ns           object\n",
       "sample       object\n",
       "split        object\n",
       "attack         bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv(\"comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>this is not creative those are the dictionary ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less npov th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>true or false the situation as of march was su...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>next maybe you could work on being less condes...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>this page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699848324</th>\n",
       "      <td>these sources dont exactly exude a sense of im...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699851288</th>\n",
       "      <td>the institute for historical review is a peerr...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699857133</th>\n",
       "      <td>the way youre trying to describe it in this ar...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699891012</th>\n",
       "      <td>warning there is clearly a protectionist regim...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699897151</th>\n",
       "      <td>alternate option is there perhaps enough newsw...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     comment  year  logged_in  \\\n",
       "rev_id                                                                          \n",
       "37675      this is not creative those are the dictionary ...  2002      False   \n",
       "44816      the term standard model is itself less npov th...  2002      False   \n",
       "49851      true or false the situation as of march was su...  2002      False   \n",
       "89320      next maybe you could work on being less condes...  2002       True   \n",
       "93890                     this page will need disambiguation  2002       True   \n",
       "...                                                      ...   ...        ...   \n",
       "699848324  these sources dont exactly exude a sense of im...  2016       True   \n",
       "699851288  the institute for historical review is a peerr...  2016       True   \n",
       "699857133  the way youre trying to describe it in this ar...  2016       True   \n",
       "699891012  warning there is clearly a protectionist regim...  2016       True   \n",
       "699897151  alternate option is there perhaps enough newsw...  2016       True   \n",
       "\n",
       "           ns  sample  split  attack  \n",
       "rev_id                                \n",
       "37675       0       1  train   False  \n",
       "44816       0       1  train   False  \n",
       "49851       0       1  train   False  \n",
       "89320       0       1    dev   False  \n",
       "93890       0       1  train   False  \n",
       "...        ..     ...    ...     ...  \n",
       "699848324   0       0  train   False  \n",
       "699851288   0       0   test   False  \n",
       "699857133   0       0  train   False  \n",
       "699891012   1       0    dev   False  \n",
       "699897151   0       0  train   False  \n",
       "\n",
       "[115864 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index([0, 1], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21952/4014800962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0menc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   9097\u001b[0m         \u001b[1;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9098\u001b[0m         \"\"\"\n\u001b[1;32m-> 9099\u001b[1;33m         return self._join_compat(\n\u001b[0m\u001b[0;32m   9100\u001b[0m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9101\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   9128\u001b[0m                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9129\u001b[0m                 )\n\u001b[1;32m-> 9130\u001b[1;33m             return merge(\n\u001b[0m\u001b[0;32m   9131\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9132\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     )\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[0;32m    718\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2307\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2308\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"columns overlap but no suffix specified: {to_rename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrenamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index([0, 1], dtype='object')"
     ]
    }
   ],
   "source": [
    "x=y=None\n",
    "data=comments\n",
    "display(comments)\n",
    "encode=['ns','sample','year']\n",
    "x=data.iloc[:,1:-1]\n",
    "y=data.iloc[:,-1]\n",
    "\n",
    "for enc in encode:\n",
    "    x[enc]=x[enc].astype('category')\n",
    "    x=x.join(pd.get_dummies(x[enc]))\n",
    "data=x.join(y)\n",
    "display(data)\n",
    "data = data.drop(columns=['comment','split'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>this is not creative those are the dictionary ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less npov th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>true or false the situation as of march was su...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>next maybe you could work on being less condes...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>this page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699848324</th>\n",
       "      <td>these sources dont exactly exude a sense of im...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699851288</th>\n",
       "      <td>the institute for historical review is a peerr...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699857133</th>\n",
       "      <td>the way youre trying to describe it in this ar...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699891012</th>\n",
       "      <td>warning there is clearly a protectionist regim...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699897151</th>\n",
       "      <td>alternate option is there perhaps enough newsw...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     comment  year  logged_in  \\\n",
       "rev_id                                                                          \n",
       "37675      this is not creative those are the dictionary ...  2002      False   \n",
       "44816      the term standard model is itself less npov th...  2002      False   \n",
       "49851      true or false the situation as of march was su...  2002      False   \n",
       "89320      next maybe you could work on being less condes...  2002       True   \n",
       "93890                     this page will need disambiguation  2002       True   \n",
       "...                                                      ...   ...        ...   \n",
       "699848324  these sources dont exactly exude a sense of im...  2016       True   \n",
       "699851288  the institute for historical review is a peerr...  2016       True   \n",
       "699857133  the way youre trying to describe it in this ar...  2016       True   \n",
       "699891012  warning there is clearly a protectionist regim...  2016       True   \n",
       "699897151  alternate option is there perhaps enough newsw...  2016       True   \n",
       "\n",
       "           ns  sample  split  attack  \n",
       "rev_id                                \n",
       "37675       0       1  train   False  \n",
       "44816       0       1  train   False  \n",
       "49851       0       1  train   False  \n",
       "89320       0       1    dev   False  \n",
       "93890       0       1  train   False  \n",
       "...        ..     ...    ...     ...  \n",
       "699848324   0       0  train   False  \n",
       "699851288   0       0   test   False  \n",
       "699857133   0       0  train   False  \n",
       "699891012   1       0    dev   False  \n",
       "699897151   0       0  train   False  \n",
       "\n",
       "[115864 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data=comments\n",
    "encode=['ns','sample']\n",
    "for x in encode:\n",
    "    data[x]=LabelEncoder().fit_transform(data[x])\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21952/992852940.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#apply SelectKBest class to extract top 10 best features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbestfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdfscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdfcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \"\"\"\n\u001b[1;32m--> 344\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n\u001b[0m\u001b[0;32m    345\u001b[0m                                    multi_output=True)\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'train'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#data = comments\n",
    "#data=data.astype(str)\n",
    "\n",
    "X = data.iloc[:,1:-1]  #independent columns\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22500/222706548.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#use inbuilt class feature_importances of tree based classifiers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#plot graph of feature importances for better visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[1;32m--> 304\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'False'"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data.iloc[:,1:-1]  #independent columns\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "X=X.astype(str)\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data= comments\n",
    "\n",
    "X = data.iloc[:,:-1]  #independent columns\n",
    "\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "\n",
    "#get correlations of each features in dataset\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22500/273973064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attack'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(self, other, method, min_periods)\u001b[0m\n\u001b[0;32m   2506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"pearson\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"spearman\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"kendall\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m             return nanops.nancorr(\n\u001b[0m\u001b[0;32m   2509\u001b[0m                 \u001b[0mthis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnancorr\u001b[1;34m(a, b, method, min_periods)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_corr_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1526\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1547\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcorrcoef\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[1;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[0;32m   2632\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[0;32m   2633\u001b[0m                       DeprecationWarning, stacklevel=3)\n\u001b[1;32m-> 2634\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2635\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2636\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2467\u001b[0m             \u001b[0mw\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0maweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2469\u001b[1;33m     \u001b[0mavg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2470\u001b[0m     \u001b[0mw_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_sum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mscl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         ret = um.true_divide(\n\u001b[0m\u001b[0;32m    181\u001b[0m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "data['ns'].corr(data['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rev_id\n",
      "37675        this is not creative those are the dictionary ...\n",
      "44816        the term standard model is itself less npov th...\n",
      "49851        true or false the situation as of march was su...\n",
      "93890                       this page will need disambiguation\n",
      "102817       important note for all sysops there is a bug i...\n",
      "                                   ...                        \n",
      "699756185    the lead itself is original research where is ...\n",
      "699813325    im talking about you making unjustified major ...\n",
      "699848324    these sources dont exactly exude a sense of im...\n",
      "699857133    the way youre trying to describe it in this ar...\n",
      "699897151    alternate option is there perhaps enough newsw...\n",
      "Name: comment, Length: 69526, dtype: object\n"
     ]
    },
    {
     "ename": "UndefinedVariableError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\scope.py\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(self, key, is_local)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_resolvers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m# support subclasses that define __missing__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36m__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\scope.py\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(self, key, is_local)\u001b[0m\n\u001b[0;32m    210\u001b[0m                 \u001b[1;31m# e.g., df[df > 0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mUndefinedVariableError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22500/1173207444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#k Cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_comments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_comments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'split'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_comments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'split'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_comments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   4058\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"level\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"level\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4059\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4060\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4062\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   4189\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"resolvers\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"resolvers\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4191\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m         )\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mparsed_expr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;31m# construct the engine and evaluate the parsed expression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_visitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPARSERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    823\u001b[0m         \u001b[0mParse\u001b[0m \u001b[0man\u001b[0m \u001b[0mexpression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \"\"\"\n\u001b[1;32m--> 825\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_visitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36mvisit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"visit_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36mvisit_Module\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"only a single expression is allowed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_Expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36mvisit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"visit_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36mvisit_Expr\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_Expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_rewrite_membership_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36mvisit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"visit_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expr.py\u001b[0m in \u001b[0;36mvisit_Name\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_Name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterm_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvisit_NameConstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, env, side, encoding)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mtname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_local\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOCAL_TAG\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDEFAULT_GLOBALS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resolve_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\ops.py\u001b[0m in \u001b[0;36m_resolve_name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_resolve_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_local\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_local\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\scope.py\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(self, key, is_local)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUndefinedVariableError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mUndefinedVariableError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_local\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mswapkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_key\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_key\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUndefinedVariableError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#k Cross validation\n",
    "print(train_comments['comment'])\n",
    "train_comments=comments[['split']].query('train')\n",
    "train_comments=comments['split'].query('test')\n",
    "display(train_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comments_nospace=train_comments[\\'comment\\'].apply(lambda x:x.replace(\" \",\"\"))\\nvectorizer=TfidfVectorizer(max_features=10000,ngram_range=(2,2),analyzer=\\'char\\')\\ntrain_comments_vectorized=vectorizer.fit_transform(comments_nospace)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''comments_nospace=train_comments['comment'].apply(lambda x:x.replace(\" \",\"\"))\n",
    "vectorizer=TfidfVectorizer(max_features=10000,ngram_range=(2,2),analyzer='char')\n",
    "train_comments_vectorized=vectorizer.fit_transform(comments_nospace)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.95      0.95     20422\n",
      "        True       0.64      0.62      0.63      2756\n",
      "\n",
      "    accuracy                           0.91     23178\n",
      "   macro avg       0.79      0.79      0.79     23178\n",
      "weighted avg       0.91      0.91      0.91     23178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19464,   958],\n",
       "       [ 1055,  1701]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "# fit classifer\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    #('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "    #('clf',LogisticRegression(random_state=0)),\n",
    "    #('clf',MultinomialNB()),\n",
    "    #('clf',RandomForestClassifier()),\n",
    "    #('clf',LinearSVC())\n",
    "])\n",
    "#clf=Pipeline([('vec',vectorizer),('clf',DecisionTreeClassifier(random_state=123))])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "y_predict=clf.predict(test_comments['comment'])\n",
    "#print(y_predict)\n",
    "#print(test_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], y_predict)\n",
    "print(met)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "display(confusion_matrix(test_comments['attack'],y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Last step of Pipeline should implement fit or be the string 'passthrough'. '[('vect', CountVectorizer(max_features=10000, ngram_range=(1, 2))), ('tfidf', TfidfTransformer()), ('smote', SMOTE(random_state=12)), ('clf', LogisticRegression(class_weight={False: 1.1, True: 8.8}, random_state=0))]' (type <class 'list'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21952/4099526912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# fit classifer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#clf = Pipeline([\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m clf=make_pipeline([\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#('vect', CountVectorizer(max_features = 10000)),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mmake_pipeline\u001b[1;34m(memory, verbose, *steps)\u001b[0m\n\u001b[0;32m    435\u001b[0m                     ('gaussiannb', GaussianNB())])\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         ):\n\u001b[1;32m--> 161\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    162\u001b[0m                 \u001b[1;34m\"Last step of Pipeline should implement fit or be \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;34m\"the string 'passthrough'. '%s' (type %s) doesn't\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Last step of Pipeline should implement fit or be the string 'passthrough'. '[('vect', CountVectorizer(max_features=10000, ngram_range=(1, 2))), ('tfidf', TfidfTransformer()), ('smote', SMOTE(random_state=12)), ('clf', LogisticRegression(class_weight={False: 1.1, True: 8.8}, random_state=0))]' (type <class 'list'>) doesn't"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.pipeline import make_pipeline\n",
    "# fit classifer\n",
    "#clf = Pipeline([\n",
    "clf=make_pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    #('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    #('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "    \n",
    "    ('clf',LogisticRegression(random_state=0,class_weight={False:1.1, True:8.8})),\n",
    "    #('clf',MultinomialNB()),\n",
    "    #('clf',RandomForestClassifier()),\n",
    "    ##('clf',LinearSVC())\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "y_predict=clf.predict(test_comments['comment'])\n",
    "#print(y_predict)\n",
    "#print(test_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], y_predict)\n",
    "print(met)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_comments['attack'],y_predict,labels=[False,True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.96     20422\n",
      "        True       0.89      0.51      0.65      2756\n",
      "\n",
      "    accuracy                           0.93     23178\n",
      "   macro avg       0.92      0.75      0.81     23178\n",
      "weighted avg       0.93      0.93      0.93     23178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20257,   165],\n",
       "       [ 1353,  1403]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2),analyzer='word')),\n",
    "    #('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    #('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "    #('clf',LogisticRegression(random_state=0)),\n",
    "    ('clf',MultinomialNB()),\n",
    "    #('clf',RandomForestClassifier()),\n",
    "    #('clf',LinearSVC())\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "y_predict=clf.predict(test_comments['comment'])\n",
    "#print(y_predict)\n",
    "#print(test_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], y_predict)\n",
    "print(met)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "display(confusion_matrix(test_comments['attack'],y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.97     20422\n",
      "        True       0.91      0.52      0.67      2756\n",
      "\n",
      "    accuracy                           0.94     23178\n",
      "   macro avg       0.93      0.76      0.82     23178\n",
      "weighted avg       0.94      0.94      0.93     23178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20286,   136],\n",
       "       [ 1313,  1443]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "# fit classifer\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    #('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    #('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "    #('clf',LogisticRegression(random_state=0)),\n",
    "    #('clf',MultinomialNB()),\n",
    "    ('clf',RandomForestClassifier()),\n",
    "    #('clf',LinearSVC())\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "y_predict=clf.predict(test_comments['comment'])\n",
    "#print(y_predict)\n",
    "#print(test_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], y_predict)\n",
    "print(met)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "display(confusion_matrix(test_comments['attack'],y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97     20422\n",
      "        True       0.86      0.64      0.73      2756\n",
      "\n",
      "    accuracy                           0.94     23178\n",
      "   macro avg       0.91      0.81      0.85     23178\n",
      "weighted avg       0.94      0.94      0.94     23178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20146,   276],\n",
       "       [ 1004,  1752]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "# fit classifer\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    #('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    #('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "    #('clf',LogisticRegression(random_state=0)),\n",
    "    #('clf',MultinomialNB()),\n",
    "    #('clf',RandomForestClassifier()),\n",
    "    ('clf',LinearSVC())\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "y_predict=clf.predict(test_comments['comment'])\n",
    "#print(y_predict)\n",
    "#print(test_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], y_predict)\n",
    "print(met)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "display(confusion_matrix(test_comments['attack'],y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi layered classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.97      0.96     20422\n",
      "        True       0.73      0.64      0.68      2756\n",
      "\n",
      "    accuracy                           0.93     23178\n",
      "   macro avg       0.84      0.80      0.82     23178\n",
      "weighted avg       0.93      0.93      0.93     23178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19785,   637],\n",
       "       [  997,  1759]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# fit classifer\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    #('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    #('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "    #('clf',LogisticRegression(random_state=0)),\n",
    "    #('clf',MultinomialNB()),\n",
    "    #('clf',RandomForestClassifier()),\n",
    "    #('clf',LinearSVC()),\n",
    "    ('clf',MLPClassifier())\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "y_predict=clf.predict(test_comments['comment'])\n",
    "#print(y_predict)\n",
    "#print(test_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], y_predict)\n",
    "print(met)\n",
    "\n",
    "\n",
    "display(confusion_matrix(test_comments['attack'],y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kCrossValidation(clf,comments):\n",
    "    kf=KFold(n_splits=10)\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    undersample= RandomUnderSampler()\n",
    "    #clf=classifier\n",
    "    X=comments['comment']\n",
    "    \n",
    "    display(type(X))\n",
    "    y=comments['attack']\n",
    "    print(type(y))\n",
    "    score_array =[]\n",
    "    confusion_matrix_array=[]\n",
    "        \n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        #print(X_train.shape)\n",
    "        #print(y_train.shape)\n",
    "        #X_train_upsample, y_train_upsample = oversample.fit_resample(X_train.to_frame(name='comment'),y_train)\n",
    "        #X_train_upsample, y_train_upsample = undersample.fit_resample(X_train.to_frame(name='comment'),y_train)\n",
    "        #print(X_train_upsample.value_counts())\n",
    "        #print(y_train_upsample.value_counts())\n",
    "        #trained_clf=clf.fit(X_train_upsample['comment'],y_train_upsample)\n",
    "        \n",
    "        #below is for imbalanced\n",
    "        print(y_train.value_counts())\n",
    "        trained_clf=clf.fit(X_train,y_train)\n",
    "        \n",
    "        \n",
    "        y_pred = trained_clf.predict(X_test)\n",
    "        score_array.append(metrics.classification_report(y_test, y_pred,output_dict=True))\n",
    "        confusion_matrix_array.append(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "    return score_array,confusion_matrix_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def getAverage(score,type_Avg):\n",
    "    avgs=defaultdict(lambda: list())\n",
    "\n",
    "    #print(score)\n",
    "    for report in score:\n",
    "        display(pd.DataFrame(report).transpose())\n",
    "        #print(report['macro avg'].keys())\n",
    "        for key in report[type_Avg].keys():\n",
    "\n",
    "            avgs[key].append(report[type_Avg][key])\n",
    "    #print(avgs)\n",
    "    for key in avgs.keys():\n",
    "        print(\"average\",key,\"=\",sum(avgs[key])/len(avgs[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracyAverage(score):\n",
    "    avgs=[]\n",
    "    for report in score:\n",
    "        avgs.append(report['accuracy'])\n",
    "    \n",
    "    print(sum(avgs)/len(avgs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(data):\n",
    "    x=data.iloc[:,0:1]\n",
    "    y=data.iloc[:,-1]\n",
    "    display(x)\n",
    "    display(y)\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    x_over, y_over = oversample.fit_resample(x, y)\n",
    "    print(x_over,y_over)\n",
    "    return x_over,y_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    91739\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n",
      "False    92089\n",
      "True     12188\n",
      "Name: attack, dtype: int64\n",
      "False    92038\n",
      "True     12239\n",
      "Name: attack, dtype: int64\n",
      "False    92126\n",
      "True     12151\n",
      "Name: attack, dtype: int64\n",
      "False    92274\n",
      "True     12004\n",
      "Name: attack, dtype: int64\n",
      "False    92238\n",
      "True     12040\n",
      "Name: attack, dtype: int64\n",
      "False    92046\n",
      "True     12232\n",
      "Name: attack, dtype: int64\n",
      "False    92032\n",
      "True     12246\n",
      "Name: attack, dtype: int64\n",
      "False    91893\n",
      "True     12385\n",
      "Name: attack, dtype: int64\n",
      "False    91991\n",
      "True     12287\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "])\n",
    "#cross_score_val(clf,comments['comment'],comments['attack'])\n",
    "#print(cross_score_val)\n",
    "\n",
    "score,confusion=kCrossValidation(clf,comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.957601</td>\n",
       "      <td>0.951875</td>\n",
       "      <td>0.954729</td>\n",
       "      <td>10535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.545291</td>\n",
       "      <td>0.577947</td>\n",
       "      <td>0.561144</td>\n",
       "      <td>1052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.917925</td>\n",
       "      <td>0.917925</td>\n",
       "      <td>0.917925</td>\n",
       "      <td>0.917925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.751446</td>\n",
       "      <td>0.764911</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.920167</td>\n",
       "      <td>0.917925</td>\n",
       "      <td>0.918995</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.957601  0.951875  0.954729  10535.000000\n",
       "True           0.545291  0.577947  0.561144   1052.000000\n",
       "accuracy       0.917925  0.917925  0.917925      0.917925\n",
       "macro avg      0.751446  0.764911  0.757937  11587.000000\n",
       "weighted avg   0.920167  0.917925  0.918995  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.944091</td>\n",
       "      <td>0.948355</td>\n",
       "      <td>0.946219</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.612094</td>\n",
       "      <td>0.592011</td>\n",
       "      <td>0.601885</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.905239</td>\n",
       "      <td>0.905239</td>\n",
       "      <td>0.905239</td>\n",
       "      <td>0.905239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.778093</td>\n",
       "      <td>0.770183</td>\n",
       "      <td>0.774052</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.903921</td>\n",
       "      <td>0.905239</td>\n",
       "      <td>0.904555</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.944091  0.948355  0.946219  10185.000000\n",
       "True           0.612094  0.592011  0.601885   1402.000000\n",
       "accuracy       0.905239  0.905239  0.905239      0.905239\n",
       "macro avg      0.778093  0.770183  0.774052  11587.000000\n",
       "weighted avg   0.903921  0.905239  0.904555  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.954118</td>\n",
       "      <td>0.950762</td>\n",
       "      <td>0.952437</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.636626</td>\n",
       "      <td>0.653590</td>\n",
       "      <td>0.644996</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.916113</td>\n",
       "      <td>0.916113</td>\n",
       "      <td>0.916113</td>\n",
       "      <td>0.916113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.795372</td>\n",
       "      <td>0.802176</td>\n",
       "      <td>0.798717</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.917099</td>\n",
       "      <td>0.916113</td>\n",
       "      <td>0.916590</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.954118  0.950762  0.952437  10236.000000\n",
       "True           0.636626  0.653590  0.644996   1351.000000\n",
       "accuracy       0.916113  0.916113  0.916113      0.916113\n",
       "macro avg      0.795372  0.802176  0.798717  11587.000000\n",
       "weighted avg   0.917099  0.916113  0.916590  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.947405</td>\n",
       "      <td>0.947872</td>\n",
       "      <td>0.947638</td>\n",
       "      <td>10148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.631102</td>\n",
       "      <td>0.628909</td>\n",
       "      <td>0.630003</td>\n",
       "      <td>1439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.908259</td>\n",
       "      <td>0.908259</td>\n",
       "      <td>0.908259</td>\n",
       "      <td>0.908259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.789253</td>\n",
       "      <td>0.788390</td>\n",
       "      <td>0.788821</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.908123</td>\n",
       "      <td>0.908259</td>\n",
       "      <td>0.908191</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.947405  0.947872  0.947638  10148.000000\n",
       "True           0.631102  0.628909  0.630003   1439.000000\n",
       "accuracy       0.908259  0.908259  0.908259      0.908259\n",
       "macro avg      0.789253  0.788390  0.788821  11587.000000\n",
       "weighted avg   0.908123  0.908259  0.908191  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.943916</td>\n",
       "      <td>0.952600</td>\n",
       "      <td>0.948238</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.643127</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.910236</td>\n",
       "      <td>0.910236</td>\n",
       "      <td>0.910236</td>\n",
       "      <td>0.910236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.813323</td>\n",
       "      <td>0.797864</td>\n",
       "      <td>0.805288</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.910236</td>\n",
       "      <td>0.909101</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.943916  0.952600  0.948238  10000.000000\n",
       "True           0.682731  0.643127  0.662338   1586.000000\n",
       "accuracy       0.910236  0.910236  0.910236      0.910236\n",
       "macro avg      0.813323  0.797864  0.805288  11586.000000\n",
       "weighted avg   0.908163  0.910236  0.909101  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.943051</td>\n",
       "      <td>0.955361</td>\n",
       "      <td>0.949166</td>\n",
       "      <td>10036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.684285</td>\n",
       "      <td>0.626452</td>\n",
       "      <td>0.654092</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.911359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.813668</td>\n",
       "      <td>0.790906</td>\n",
       "      <td>0.801629</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.908433</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.909690</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.943051  0.955361  0.949166  10036.000000\n",
       "True           0.684285  0.626452  0.654092   1550.000000\n",
       "accuracy       0.911359  0.911359  0.911359      0.911359\n",
       "macro avg      0.813668  0.790906  0.801629  11586.000000\n",
       "weighted avg   0.908433  0.911359  0.909690  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.949280</td>\n",
       "      <td>0.947888</td>\n",
       "      <td>0.948584</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.611799</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.615159</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.909287</td>\n",
       "      <td>0.909287</td>\n",
       "      <td>0.909287</td>\n",
       "      <td>0.909287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.780540</td>\n",
       "      <td>0.783222</td>\n",
       "      <td>0.781872</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.909724</td>\n",
       "      <td>0.909287</td>\n",
       "      <td>0.909503</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.949280  0.947888  0.948584  10228.000000\n",
       "True           0.611799  0.618557  0.615159   1358.000000\n",
       "accuracy       0.909287  0.909287  0.909287      0.909287\n",
       "macro avg      0.780540  0.783222  0.781872  11586.000000\n",
       "weighted avg   0.909724  0.909287  0.909503  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.952460</td>\n",
       "      <td>0.954599</td>\n",
       "      <td>0.953528</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.647994</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.642402</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.800227</td>\n",
       "      <td>0.795752</td>\n",
       "      <td>0.797965</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.917141</td>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917437</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.952460  0.954599  0.953528  10242.000000\n",
       "True           0.647994  0.636905  0.642402   1344.000000\n",
       "accuracy       0.917746  0.917746  0.917746      0.917746\n",
       "macro avg      0.800227  0.795752  0.797965  11586.000000\n",
       "weighted avg   0.917141  0.917746  0.917437  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.955313</td>\n",
       "      <td>0.953473</td>\n",
       "      <td>0.954392</td>\n",
       "      <td>10381.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.605714</td>\n",
       "      <td>0.615768</td>\n",
       "      <td>0.610700</td>\n",
       "      <td>1205.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.918350</td>\n",
       "      <td>0.918350</td>\n",
       "      <td>0.918350</td>\n",
       "      <td>0.91835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.780514</td>\n",
       "      <td>0.784620</td>\n",
       "      <td>0.782546</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.918953</td>\n",
       "      <td>0.918350</td>\n",
       "      <td>0.918646</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.955313  0.953473  0.954392  10381.00000\n",
       "True           0.605714  0.615768  0.610700   1205.00000\n",
       "accuracy       0.918350  0.918350  0.918350      0.91835\n",
       "macro avg      0.780514  0.784620  0.782546  11586.00000\n",
       "weighted avg   0.918953  0.918350  0.918646  11586.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.949253</td>\n",
       "      <td>0.951376</td>\n",
       "      <td>0.950313</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.598619</td>\n",
       "      <td>0.603949</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.911704</td>\n",
       "      <td>0.911704</td>\n",
       "      <td>0.911704</td>\n",
       "      <td>0.911704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.779314</td>\n",
       "      <td>0.774997</td>\n",
       "      <td>0.777131</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.911704</td>\n",
       "      <td>0.911360</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.949253  0.951376  0.950313  10283.000000\n",
       "True           0.609375  0.598619  0.603949   1303.000000\n",
       "accuracy       0.911704  0.911704  0.911704      0.911704\n",
       "macro avg      0.779314  0.774997  0.777131  11586.000000\n",
       "weighted avg   0.911029  0.911704  0.911360  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.788174981257115\n",
      "average recall = 0.7853021841515501\n",
      "average f1-score = 0.7865956526207409\n",
      "average support = 11586.4\n",
      "0.912621719868533\n",
      "[array([[10028,   507],\n",
      "       [  444,   608]], dtype=int64), array([[9659,  526],\n",
      "       [ 572,  830]], dtype=int64), array([[9732,  504],\n",
      "       [ 468,  883]], dtype=int64), array([[9619,  529],\n",
      "       [ 534,  905]], dtype=int64), array([[9526,  474],\n",
      "       [ 566, 1020]], dtype=int64), array([[9588,  448],\n",
      "       [ 579,  971]], dtype=int64), array([[9695,  533],\n",
      "       [ 518,  840]], dtype=int64), array([[9777,  465],\n",
      "       [ 488,  856]], dtype=int64), array([[9898,  483],\n",
      "       [ 463,  742]], dtype=int64), array([[9783,  500],\n",
      "       [ 523,  780]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(104277, 2)\n",
      "(104277,)\n",
      "False    91739\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6844/1343267839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#print(cross_score_val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkCrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6844/3755754630.py\u001b[0m in \u001b[0;36mkCrossValidation\u001b[1;34m(clf, comments)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m#below is for imbalanced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtrained_clf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',LogisticRegression(random_state=0,max_iter=1000)),\n",
    "])\n",
    "#cross_score_val(clf,comments['comment'],comments['attack'])\n",
    "#print(cross_score_val)\n",
    "\n",
    "score,confusion=kCrossValidation(clf,comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.956506</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.972706</td>\n",
       "      <td>10535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.549430</td>\n",
       "      <td>0.663986</td>\n",
       "      <td>1052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.949512</td>\n",
       "      <td>0.949512</td>\n",
       "      <td>0.949512</td>\n",
       "      <td>0.949512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.897701</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.818346</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.945828</td>\n",
       "      <td>0.949512</td>\n",
       "      <td>0.944677</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.956506  0.989464  0.972706  10535.000000\n",
       "True           0.838897  0.549430  0.663986   1052.000000\n",
       "accuracy       0.949512  0.949512  0.949512      0.949512\n",
       "macro avg      0.897701  0.769447  0.818346  11587.000000\n",
       "weighted avg   0.945828  0.949512  0.944677  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.943727</td>\n",
       "      <td>0.989593</td>\n",
       "      <td>0.966116</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.883131</td>\n",
       "      <td>0.571327</td>\n",
       "      <td>0.693807</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.938983</td>\n",
       "      <td>0.938983</td>\n",
       "      <td>0.938983</td>\n",
       "      <td>0.938983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.913429</td>\n",
       "      <td>0.780460</td>\n",
       "      <td>0.829961</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.936395</td>\n",
       "      <td>0.938983</td>\n",
       "      <td>0.933167</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.943727  0.989593  0.966116  10185.000000\n",
       "True           0.883131  0.571327  0.693807   1402.000000\n",
       "accuracy       0.938983  0.938983  0.938983      0.938983\n",
       "macro avg      0.913429  0.780460  0.829961  11587.000000\n",
       "weighted avg   0.936395  0.938983  0.933167  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.952676</td>\n",
       "      <td>0.991208</td>\n",
       "      <td>0.971560</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.903949</td>\n",
       "      <td>0.626943</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.948736</td>\n",
       "      <td>0.948736</td>\n",
       "      <td>0.948736</td>\n",
       "      <td>0.948736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.928312</td>\n",
       "      <td>0.809075</td>\n",
       "      <td>0.855972</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.946995</td>\n",
       "      <td>0.948736</td>\n",
       "      <td>0.944606</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.952676  0.991208  0.971560  10236.000000\n",
       "True           0.903949  0.626943  0.740385   1351.000000\n",
       "accuracy       0.948736  0.948736  0.948736      0.948736\n",
       "macro avg      0.928312  0.809075  0.855972  11587.000000\n",
       "weighted avg   0.946995  0.948736  0.944606  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.990343</td>\n",
       "      <td>0.966439</td>\n",
       "      <td>10148.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.895411</td>\n",
       "      <td>0.583044</td>\n",
       "      <td>0.706229</td>\n",
       "      <td>1439.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939760</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>0.93976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.919536</td>\n",
       "      <td>0.786693</td>\n",
       "      <td>0.836334</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.937670</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>0.934123</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.943662  0.990343  0.966439  10148.00000\n",
       "True           0.895411  0.583044  0.706229   1439.00000\n",
       "accuracy       0.939760  0.939760  0.939760      0.93976\n",
       "macro avg      0.919536  0.786693  0.836334  11587.00000\n",
       "weighted avg   0.937670  0.939760  0.934123  11587.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.944264</td>\n",
       "      <td>0.987700</td>\n",
       "      <td>0.965494</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.890764</td>\n",
       "      <td>0.632409</td>\n",
       "      <td>0.739676</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939064</td>\n",
       "      <td>0.939064</td>\n",
       "      <td>0.939064</td>\n",
       "      <td>0.939064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.917514</td>\n",
       "      <td>0.810054</td>\n",
       "      <td>0.852585</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.936940</td>\n",
       "      <td>0.939064</td>\n",
       "      <td>0.934582</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.944264  0.987700  0.965494  10000.000000\n",
       "True           0.890764  0.632409  0.739676   1586.000000\n",
       "accuracy       0.939064  0.939064  0.939064      0.939064\n",
       "macro avg      0.917514  0.810054  0.852585  11586.000000\n",
       "weighted avg   0.936940  0.939064  0.934582  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.943278</td>\n",
       "      <td>0.989239</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>10036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.898209</td>\n",
       "      <td>0.614839</td>\n",
       "      <td>0.729989</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939151</td>\n",
       "      <td>0.939151</td>\n",
       "      <td>0.939151</td>\n",
       "      <td>0.939151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.920744</td>\n",
       "      <td>0.802039</td>\n",
       "      <td>0.847850</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.937249</td>\n",
       "      <td>0.939151</td>\n",
       "      <td>0.934176</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.943278  0.989239  0.965712  10036.000000\n",
       "True           0.898209  0.614839  0.729989   1550.000000\n",
       "accuracy       0.939151  0.939151  0.939151      0.939151\n",
       "macro avg      0.920744  0.802039  0.847850  11586.000000\n",
       "weighted avg   0.937249  0.939151  0.934176  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.948059</td>\n",
       "      <td>0.988659</td>\n",
       "      <td>0.967933</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.873913</td>\n",
       "      <td>0.592047</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.942172</td>\n",
       "      <td>0.942172</td>\n",
       "      <td>0.942172</td>\n",
       "      <td>0.942172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.910986</td>\n",
       "      <td>0.790353</td>\n",
       "      <td>0.836908</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.939369</td>\n",
       "      <td>0.942172</td>\n",
       "      <td>0.937218</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.948059  0.988659  0.967933  10228.000000\n",
       "True           0.873913  0.592047  0.705882   1358.000000\n",
       "accuracy       0.942172  0.942172  0.942172      0.942172\n",
       "macro avg      0.910986  0.790353  0.836908  11586.000000\n",
       "weighted avg   0.939369  0.942172  0.937218  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.949560</td>\n",
       "      <td>0.990724</td>\n",
       "      <td>0.969706</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.717469</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.945279</td>\n",
       "      <td>0.945279</td>\n",
       "      <td>0.945279</td>\n",
       "      <td>0.945279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.922002</td>\n",
       "      <td>0.794841</td>\n",
       "      <td>0.843587</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.943167</td>\n",
       "      <td>0.945279</td>\n",
       "      <td>0.940446</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.949560  0.990724  0.969706  10242.000000\n",
       "True           0.894444  0.598958  0.717469   1344.000000\n",
       "accuracy       0.945279  0.945279  0.945279      0.945279\n",
       "macro avg      0.922002  0.794841  0.843587  11586.000000\n",
       "weighted avg   0.943167  0.945279  0.940446  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.953935</td>\n",
       "      <td>0.991427</td>\n",
       "      <td>0.972319</td>\n",
       "      <td>10381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.888331</td>\n",
       "      <td>0.587552</td>\n",
       "      <td>0.707293</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.949422</td>\n",
       "      <td>0.949422</td>\n",
       "      <td>0.949422</td>\n",
       "      <td>0.949422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.921133</td>\n",
       "      <td>0.789489</td>\n",
       "      <td>0.839806</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.947112</td>\n",
       "      <td>0.949422</td>\n",
       "      <td>0.944755</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.953935  0.991427  0.972319  10381.000000\n",
       "True           0.888331  0.587552  0.707293   1205.000000\n",
       "accuracy       0.949422  0.949422  0.949422      0.949422\n",
       "macro avg      0.921133  0.789489  0.839806  11586.000000\n",
       "weighted avg   0.947112  0.949422  0.944755  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.946688</td>\n",
       "      <td>0.989497</td>\n",
       "      <td>0.967619</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.871122</td>\n",
       "      <td>0.560246</td>\n",
       "      <td>0.681924</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.941222</td>\n",
       "      <td>0.941222</td>\n",
       "      <td>0.941222</td>\n",
       "      <td>0.941222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.908905</td>\n",
       "      <td>0.774871</td>\n",
       "      <td>0.824772</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.938189</td>\n",
       "      <td>0.941222</td>\n",
       "      <td>0.935489</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.946688  0.989497  0.967619  10283.000000\n",
       "True           0.871122  0.560246  0.681924   1303.000000\n",
       "accuracy       0.941222  0.941222  0.941222      0.941222\n",
       "macro avg      0.908905  0.774871  0.824772  11586.000000\n",
       "weighted avg   0.938189  0.941222  0.935489  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.9160262590266786\n",
      "average recall = 0.790732282207823\n",
      "average f1-score = 0.8386120996558303\n",
      "average support = 11586.4\n",
      "0.9433300794799246\n"
     ]
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive baye "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    12538\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n",
      "False    12188\n",
      "True     12188\n",
      "Name: attack, dtype: int64\n",
      "False    12239\n",
      "True     12239\n",
      "Name: attack, dtype: int64\n",
      "False    12151\n",
      "True     12151\n",
      "Name: attack, dtype: int64\n",
      "False    12004\n",
      "True     12004\n",
      "Name: attack, dtype: int64\n",
      "False    12040\n",
      "True     12040\n",
      "Name: attack, dtype: int64\n",
      "False    12232\n",
      "True     12232\n",
      "Name: attack, dtype: int64\n",
      "False    12246\n",
      "True     12246\n",
      "Name: attack, dtype: int64\n",
      "False    12385\n",
      "True     12385\n",
      "Name: attack, dtype: int64\n",
      "False    12287\n",
      "True     12287\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "#cross_score_val(clf,comments['comment'],comments['attack'])\n",
    "#print(cross_score_val)\n",
    "\n",
    "score,confusion=kCrossValidation(clf,comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.869862</td>\n",
       "      <td>0.921839</td>\n",
       "      <td>10535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.387946</td>\n",
       "      <td>0.826046</td>\n",
       "      <td>0.527947</td>\n",
       "      <td>1052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.865884</td>\n",
       "      <td>0.865884</td>\n",
       "      <td>0.865884</td>\n",
       "      <td>0.865884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.684184</td>\n",
       "      <td>0.847954</td>\n",
       "      <td>0.724893</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.926630</td>\n",
       "      <td>0.865884</td>\n",
       "      <td>0.886077</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.980422  0.869862  0.921839  10535.000000\n",
       "True           0.387946  0.826046  0.527947   1052.000000\n",
       "accuracy       0.865884  0.865884  0.865884      0.865884\n",
       "macro avg      0.684184  0.847954  0.724893  11587.000000\n",
       "weighted avg   0.926630  0.865884  0.886077  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.973033</td>\n",
       "      <td>0.853805</td>\n",
       "      <td>0.909528</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.438113</td>\n",
       "      <td>0.828103</td>\n",
       "      <td>0.573050</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.850695</td>\n",
       "      <td>0.850695</td>\n",
       "      <td>0.850695</td>\n",
       "      <td>0.850695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.705573</td>\n",
       "      <td>0.840954</td>\n",
       "      <td>0.741289</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.908309</td>\n",
       "      <td>0.850695</td>\n",
       "      <td>0.868815</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.973033  0.853805  0.909528  10185.000000\n",
       "True           0.438113  0.828103  0.573050   1402.000000\n",
       "accuracy       0.850695  0.850695  0.850695      0.850695\n",
       "macro avg      0.705573  0.840954  0.741289  11587.000000\n",
       "weighted avg   0.908309  0.850695  0.868815  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.862837</td>\n",
       "      <td>0.918278</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.457286</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>0.600813</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.864331</td>\n",
       "      <td>0.864331</td>\n",
       "      <td>0.864331</td>\n",
       "      <td>0.864331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.719310</td>\n",
       "      <td>0.869242</td>\n",
       "      <td>0.759545</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.920231</td>\n",
       "      <td>0.864331</td>\n",
       "      <td>0.881263</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.981333  0.862837  0.918278  10236.000000\n",
       "True           0.457286  0.875648  0.600813   1351.000000\n",
       "accuracy       0.864331  0.864331  0.864331      0.864331\n",
       "macro avg      0.719310  0.869242  0.759545  11587.000000\n",
       "weighted avg   0.920231  0.864331  0.881263  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.977664</td>\n",
       "      <td>0.845388</td>\n",
       "      <td>0.906727</td>\n",
       "      <td>10148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.442034</td>\n",
       "      <td>0.863794</td>\n",
       "      <td>0.584804</td>\n",
       "      <td>1439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.847674</td>\n",
       "      <td>0.847674</td>\n",
       "      <td>0.847674</td>\n",
       "      <td>0.847674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.709849</td>\n",
       "      <td>0.854591</td>\n",
       "      <td>0.745765</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.911143</td>\n",
       "      <td>0.847674</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.977664  0.845388  0.906727  10148.000000\n",
       "True           0.442034  0.863794  0.584804   1439.000000\n",
       "accuracy       0.847674  0.847674  0.847674      0.847674\n",
       "macro avg      0.709849  0.854591  0.745765  11587.000000\n",
       "weighted avg   0.911143  0.847674  0.866747  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.975340</td>\n",
       "      <td>0.846400</td>\n",
       "      <td>0.906307</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.471802</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>0.610592</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.848956</td>\n",
       "      <td>0.848956</td>\n",
       "      <td>0.848956</td>\n",
       "      <td>0.848956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.723571</td>\n",
       "      <td>0.855735</td>\n",
       "      <td>0.758449</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.906411</td>\n",
       "      <td>0.848956</td>\n",
       "      <td>0.865827</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.975340  0.846400  0.906307  10000.000000\n",
       "True           0.471802  0.865069  0.610592   1586.000000\n",
       "accuracy       0.848956  0.848956  0.848956      0.848956\n",
       "macro avg      0.723571  0.855735  0.758449  11586.000000\n",
       "weighted avg   0.906411  0.848956  0.865827  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.978588</td>\n",
       "      <td>0.856118</td>\n",
       "      <td>0.913265</td>\n",
       "      <td>10036.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.485388</td>\n",
       "      <td>0.878710</td>\n",
       "      <td>0.625344</td>\n",
       "      <td>1550.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.859140</td>\n",
       "      <td>0.859140</td>\n",
       "      <td>0.859140</td>\n",
       "      <td>0.85914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.731988</td>\n",
       "      <td>0.867414</td>\n",
       "      <td>0.769305</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.912606</td>\n",
       "      <td>0.859140</td>\n",
       "      <td>0.874747</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.978588  0.856118  0.913265  10036.00000\n",
       "True           0.485388  0.878710  0.625344   1550.00000\n",
       "accuracy       0.859140  0.859140  0.859140      0.85914\n",
       "macro avg      0.731988  0.867414  0.769305  11586.00000\n",
       "weighted avg   0.912606  0.859140  0.874747  11586.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.864490</td>\n",
       "      <td>0.918554</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.864664</td>\n",
       "      <td>0.864664</td>\n",
       "      <td>0.864664</td>\n",
       "      <td>0.864664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.719424</td>\n",
       "      <td>0.865235</td>\n",
       "      <td>0.759277</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.918787</td>\n",
       "      <td>0.864664</td>\n",
       "      <td>0.881216</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.979832  0.864490  0.918554  10228.000000\n",
       "True           0.459016  0.865979  0.600000   1358.000000\n",
       "accuracy       0.864664  0.864664  0.864664      0.864664\n",
       "macro avg      0.719424  0.865235  0.759277  11586.000000\n",
       "weighted avg   0.918787  0.864664  0.881216  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.980086</td>\n",
       "      <td>0.869752</td>\n",
       "      <td>0.921628</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.465759</td>\n",
       "      <td>0.865327</td>\n",
       "      <td>0.605571</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.869239</td>\n",
       "      <td>0.869239</td>\n",
       "      <td>0.869239</td>\n",
       "      <td>0.869239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.722922</td>\n",
       "      <td>0.867540</td>\n",
       "      <td>0.763600</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.920423</td>\n",
       "      <td>0.869239</td>\n",
       "      <td>0.884965</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.980086  0.869752  0.921628  10242.000000\n",
       "True           0.465759  0.865327  0.605571   1344.000000\n",
       "accuracy       0.869239  0.869239  0.869239      0.869239\n",
       "macro avg      0.722922  0.867540  0.763600  11586.000000\n",
       "weighted avg   0.920423  0.869239  0.884965  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.877565</td>\n",
       "      <td>0.926190</td>\n",
       "      <td>10381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.446187</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.585143</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.874676</td>\n",
       "      <td>0.874676</td>\n",
       "      <td>0.874676</td>\n",
       "      <td>0.874676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.713353</td>\n",
       "      <td>0.863679</td>\n",
       "      <td>0.755666</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.924946</td>\n",
       "      <td>0.874676</td>\n",
       "      <td>0.890719</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.980519  0.877565  0.926190  10381.000000\n",
       "True           0.446187  0.849793  0.585143   1205.000000\n",
       "accuracy       0.874676  0.874676  0.874676      0.874676\n",
       "macro avg      0.713353  0.863679  0.755666  11586.000000\n",
       "weighted avg   0.924946  0.874676  0.890719  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.973678</td>\n",
       "      <td>0.870563</td>\n",
       "      <td>0.919238</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.443562</td>\n",
       "      <td>0.814275</td>\n",
       "      <td>0.574290</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.864233</td>\n",
       "      <td>0.864233</td>\n",
       "      <td>0.864233</td>\n",
       "      <td>0.864233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.708620</td>\n",
       "      <td>0.842419</td>\n",
       "      <td>0.746764</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.914060</td>\n",
       "      <td>0.864233</td>\n",
       "      <td>0.880444</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.973678  0.870563  0.919238  10283.000000\n",
       "True           0.443562  0.814275  0.574290   1303.000000\n",
       "accuracy       0.864233  0.864233  0.864233      0.864233\n",
       "macro avg      0.708620  0.842419  0.746764  11586.000000\n",
       "weighted avg   0.914060  0.864233  0.880444  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.7138794772960845\n",
      "average recall = 0.8574761562059654\n",
      "average f1-score = 0.7524554003079439\n",
      "average support = 11586.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8609491750064071"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    91739\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n",
      "False    92089\n",
      "True     12188\n",
      "Name: attack, dtype: int64\n",
      "False    92038\n",
      "True     12239\n",
      "Name: attack, dtype: int64\n",
      "False    92126\n",
      "True     12151\n",
      "Name: attack, dtype: int64\n",
      "False    92274\n",
      "True     12004\n",
      "Name: attack, dtype: int64\n",
      "False    92238\n",
      "True     12040\n",
      "Name: attack, dtype: int64\n",
      "False    92046\n",
      "True     12232\n",
      "Name: attack, dtype: int64\n",
      "False    92032\n",
      "True     12246\n",
      "Name: attack, dtype: int64\n",
      "False    91893\n",
      "True     12385\n",
      "Name: attack, dtype: int64\n",
      "False    91991\n",
      "True     12287\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',RandomForestClassifier()),\n",
    "])\n",
    "#cross_score_val(clf,comments['comment'],comments['attack'])\n",
    "#print(cross_score_val)\n",
    "\n",
    "score,confusion=kCrossValidation(clf,comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.951226</td>\n",
       "      <td>0.994115</td>\n",
       "      <td>0.972198</td>\n",
       "      <td>10535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.892548</td>\n",
       "      <td>0.489544</td>\n",
       "      <td>0.632290</td>\n",
       "      <td>1052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.948304</td>\n",
       "      <td>0.948304</td>\n",
       "      <td>0.948304</td>\n",
       "      <td>0.948304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.921887</td>\n",
       "      <td>0.741829</td>\n",
       "      <td>0.802244</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.945899</td>\n",
       "      <td>0.948304</td>\n",
       "      <td>0.941337</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.951226  0.994115  0.972198  10535.000000\n",
       "True           0.892548  0.489544  0.632290   1052.000000\n",
       "accuracy       0.948304  0.948304  0.948304      0.948304\n",
       "macro avg      0.921887  0.741829  0.802244  11587.000000\n",
       "weighted avg   0.945899  0.948304  0.941337  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.935081</td>\n",
       "      <td>0.991360</td>\n",
       "      <td>0.962398</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.888466</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.639890</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.931906</td>\n",
       "      <td>0.931906</td>\n",
       "      <td>0.931906</td>\n",
       "      <td>0.931906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.911773</td>\n",
       "      <td>0.745680</td>\n",
       "      <td>0.801144</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.929440</td>\n",
       "      <td>0.931906</td>\n",
       "      <td>0.923375</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.935081  0.991360  0.962398  10185.000000\n",
       "True           0.888466  0.500000  0.639890   1402.000000\n",
       "accuracy       0.931906  0.931906  0.931906      0.931906\n",
       "macro avg      0.911773  0.745680  0.801144  11587.000000\n",
       "weighted avg   0.929440  0.931906  0.923375  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.945835</td>\n",
       "      <td>0.992868</td>\n",
       "      <td>0.968781</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.913302</td>\n",
       "      <td>0.569208</td>\n",
       "      <td>0.701322</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.943471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.929568</td>\n",
       "      <td>0.781038</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.942042</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.937597</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.945835  0.992868  0.968781  10236.000000\n",
       "True           0.913302  0.569208  0.701322   1351.000000\n",
       "accuracy       0.943471  0.943471  0.943471      0.943471\n",
       "macro avg      0.929568  0.781038  0.835052  11587.000000\n",
       "weighted avg   0.942042  0.943471  0.937597  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.936849</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>0.963923</td>\n",
       "      <td>10148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.910180</td>\n",
       "      <td>0.528145</td>\n",
       "      <td>0.668426</td>\n",
       "      <td>1439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.934927</td>\n",
       "      <td>0.934927</td>\n",
       "      <td>0.934927</td>\n",
       "      <td>0.934927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.923514</td>\n",
       "      <td>0.760377</td>\n",
       "      <td>0.816175</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.933537</td>\n",
       "      <td>0.934927</td>\n",
       "      <td>0.927225</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.936849  0.992609  0.963923  10148.000000\n",
       "True           0.910180  0.528145  0.668426   1439.000000\n",
       "accuracy       0.934927  0.934927  0.934927      0.934927\n",
       "macro avg      0.923514  0.760377  0.816175  11587.000000\n",
       "weighted avg   0.933537  0.934927  0.927225  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.935264</td>\n",
       "      <td>0.988200</td>\n",
       "      <td>0.961004</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>0.568726</td>\n",
       "      <td>0.692249</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.930779</td>\n",
       "      <td>0.930779</td>\n",
       "      <td>0.930779</td>\n",
       "      <td>0.930779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.909789</td>\n",
       "      <td>0.778463</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.930779</td>\n",
       "      <td>0.924214</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.935264  0.988200  0.961004  10000.000000\n",
       "True           0.884314  0.568726  0.692249   1586.000000\n",
       "accuracy       0.930779  0.930779  0.930779      0.930779\n",
       "macro avg      0.909789  0.778463  0.826626  11586.000000\n",
       "weighted avg   0.928289  0.930779  0.924214  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.934442</td>\n",
       "      <td>0.991331</td>\n",
       "      <td>0.962046</td>\n",
       "      <td>10036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.907348</td>\n",
       "      <td>0.549677</td>\n",
       "      <td>0.684612</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.932246</td>\n",
       "      <td>0.932246</td>\n",
       "      <td>0.932246</td>\n",
       "      <td>0.932246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.920895</td>\n",
       "      <td>0.770504</td>\n",
       "      <td>0.823329</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.930817</td>\n",
       "      <td>0.932246</td>\n",
       "      <td>0.924930</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.934442  0.991331  0.962046  10036.000000\n",
       "True           0.907348  0.549677  0.684612   1550.000000\n",
       "accuracy       0.932246  0.932246  0.932246      0.932246\n",
       "macro avg      0.920895  0.770504  0.823329  11586.000000\n",
       "weighted avg   0.930817  0.932246  0.924930  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.939383</td>\n",
       "      <td>0.990907</td>\n",
       "      <td>0.964457</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.883312</td>\n",
       "      <td>0.518409</td>\n",
       "      <td>0.653364</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.935526</td>\n",
       "      <td>0.935526</td>\n",
       "      <td>0.935526</td>\n",
       "      <td>0.935526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.911348</td>\n",
       "      <td>0.754658</td>\n",
       "      <td>0.808911</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.932811</td>\n",
       "      <td>0.935526</td>\n",
       "      <td>0.927994</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.939383  0.990907  0.964457  10228.000000\n",
       "True           0.883312  0.518409  0.653364   1358.000000\n",
       "accuracy       0.935526  0.935526  0.935526      0.935526\n",
       "macro avg      0.911348  0.754658  0.808911  11586.000000\n",
       "weighted avg   0.932811  0.935526  0.927994  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.941029</td>\n",
       "      <td>0.992482</td>\n",
       "      <td>0.966071</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.664474</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.938374</td>\n",
       "      <td>0.938374</td>\n",
       "      <td>0.938374</td>\n",
       "      <td>0.938374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.921408</td>\n",
       "      <td>0.759262</td>\n",
       "      <td>0.815272</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.936477</td>\n",
       "      <td>0.938374</td>\n",
       "      <td>0.931085</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.941029  0.992482  0.966071  10242.000000\n",
       "True           0.901786  0.526042  0.664474   1344.000000\n",
       "accuracy       0.938374  0.938374  0.938374      0.938374\n",
       "macro avg      0.921408  0.759262  0.815272  11586.000000\n",
       "weighted avg   0.936477  0.938374  0.931085  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.948926</td>\n",
       "      <td>0.991523</td>\n",
       "      <td>0.969757</td>\n",
       "      <td>10381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.880920</td>\n",
       "      <td>0.540249</td>\n",
       "      <td>0.669753</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.944588</td>\n",
       "      <td>0.944588</td>\n",
       "      <td>0.944588</td>\n",
       "      <td>0.944588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.914923</td>\n",
       "      <td>0.765886</td>\n",
       "      <td>0.819755</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.941853</td>\n",
       "      <td>0.944588</td>\n",
       "      <td>0.938555</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.948926  0.991523  0.969757  10381.000000\n",
       "True           0.880920  0.540249  0.669753   1205.000000\n",
       "accuracy       0.944588  0.944588  0.944588      0.944588\n",
       "macro avg      0.914923  0.765886  0.819755  11586.000000\n",
       "weighted avg   0.941853  0.944588  0.938555  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.941301</td>\n",
       "      <td>0.991831</td>\n",
       "      <td>0.965906</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.888149</td>\n",
       "      <td>0.511896</td>\n",
       "      <td>0.649464</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.937856</td>\n",
       "      <td>0.937856</td>\n",
       "      <td>0.937856</td>\n",
       "      <td>0.937856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.914725</td>\n",
       "      <td>0.751863</td>\n",
       "      <td>0.807685</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.935324</td>\n",
       "      <td>0.937856</td>\n",
       "      <td>0.930318</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.941301  0.991831  0.965906  10283.000000\n",
       "True           0.888149  0.511896  0.649464   1303.000000\n",
       "accuracy       0.937856  0.937856  0.937856      0.937856\n",
       "macro avg      0.914725  0.751863  0.807685  11586.000000\n",
       "weighted avg   0.935324  0.937856  0.930318  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.9179830435228583\n",
      "average recall = 0.7609561359071275\n",
      "average f1-score = 0.8156193127420401\n",
      "average support = 11586.4\n",
      "0.9377976988711746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[10473,    62],\n",
       "        [  537,   515]], dtype=int64),\n",
       " array([[10097,    88],\n",
       "        [  701,   701]], dtype=int64),\n",
       " array([[10163,    73],\n",
       "        [  582,   769]], dtype=int64),\n",
       " array([[10073,    75],\n",
       "        [  679,   760]], dtype=int64),\n",
       " array([[9882,  118],\n",
       "        [ 684,  902]], dtype=int64),\n",
       " array([[9949,   87],\n",
       "        [ 698,  852]], dtype=int64),\n",
       " array([[10135,    93],\n",
       "        [  654,   704]], dtype=int64),\n",
       " array([[10165,    77],\n",
       "        [  637,   707]], dtype=int64),\n",
       " array([[10293,    88],\n",
       "        [  554,   651]], dtype=int64),\n",
       " array([[10199,    84],\n",
       "        [  636,   667]], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    91739\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n",
      "False    92089\n",
      "True     12188\n",
      "Name: attack, dtype: int64\n",
      "False    92038\n",
      "True     12239\n",
      "Name: attack, dtype: int64\n",
      "False    92126\n",
      "True     12151\n",
      "Name: attack, dtype: int64\n",
      "False    92274\n",
      "True     12004\n",
      "Name: attack, dtype: int64\n",
      "False    92238\n",
      "True     12040\n",
      "Name: attack, dtype: int64\n",
      "False    92046\n",
      "True     12232\n",
      "Name: attack, dtype: int64\n",
      "False    92032\n",
      "True     12246\n",
      "Name: attack, dtype: int64\n",
      "False    91893\n",
      "True     12385\n",
      "Name: attack, dtype: int64\n",
      "False    91991\n",
      "True     12287\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',LinearSVC(class_weight={False:1,True:4},C=0.1,loss='squared_hinge'))\n",
    "])\n",
    "score,confusion=kCrossValidation(clf,comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.975400</td>\n",
       "      <td>0.959753</td>\n",
       "      <td>0.967514</td>\n",
       "      <td>10535.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.652744</td>\n",
       "      <td>0.757605</td>\n",
       "      <td>0.701276</td>\n",
       "      <td>1052.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.814072</td>\n",
       "      <td>0.858679</td>\n",
       "      <td>0.834395</td>\n",
       "      <td>11587.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.946106</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.943341</td>\n",
       "      <td>11587.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          0.975400  0.959753  0.967514  10535.0000\n",
       "True           0.652744  0.757605  0.701276   1052.0000\n",
       "accuracy       0.941400  0.941400  0.941400      0.9414\n",
       "macro avg      0.814072  0.858679  0.834395  11587.0000\n",
       "weighted avg   0.946106  0.941400  0.943341  11587.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.952774</td>\n",
       "      <td>0.959557</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.688875</td>\n",
       "      <td>0.759629</td>\n",
       "      <td>0.722524</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.929404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.827656</td>\n",
       "      <td>0.856201</td>\n",
       "      <td>0.841040</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.932853</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.930877</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.966438  0.952774  0.959557  10185.000000\n",
       "True           0.688875  0.759629  0.722524   1402.000000\n",
       "accuracy       0.929404  0.929404  0.929404      0.929404\n",
       "macro avg      0.827656  0.856201  0.841040  11587.000000\n",
       "weighted avg   0.932853  0.929404  0.930877  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.973791</td>\n",
       "      <td>0.961899</td>\n",
       "      <td>0.967809</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.735772</td>\n",
       "      <td>0.803849</td>\n",
       "      <td>0.768306</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.943471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.854782</td>\n",
       "      <td>0.882874</td>\n",
       "      <td>0.868057</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.946039</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.944547</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.973791  0.961899  0.967809  10236.000000\n",
       "True           0.735772  0.803849  0.768306   1351.000000\n",
       "accuracy       0.943471  0.943471  0.943471      0.943471\n",
       "macro avg      0.854782  0.882874  0.868057  11587.000000\n",
       "weighted avg   0.946039  0.943471  0.944547  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.960778</td>\n",
       "      <td>10148.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.779013</td>\n",
       "      <td>0.739446</td>\n",
       "      <td>1439.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.93182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.835942</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.850112</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.935335</td>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.933291</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.968181  0.953488  0.960778  10148.00000\n",
       "True           0.703704  0.779013  0.739446   1439.00000\n",
       "accuracy       0.931820  0.931820  0.931820      0.93182\n",
       "macro avg      0.835942  0.866251  0.850112  11587.00000\n",
       "weighted avg   0.935335  0.931820  0.933291  11587.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.965321</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.958614</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.721578</td>\n",
       "      <td>0.784363</td>\n",
       "      <td>0.751662</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.929052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.843450</td>\n",
       "      <td>0.868182</td>\n",
       "      <td>0.855138</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.931956</td>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.930285</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.965321  0.952000  0.958614  10000.000000\n",
       "True           0.721578  0.784363  0.751662   1586.000000\n",
       "accuracy       0.929052  0.929052  0.929052      0.929052\n",
       "macro avg      0.843450  0.868182  0.855138  11586.000000\n",
       "weighted avg   0.931956  0.929052  0.930285  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.967580</td>\n",
       "      <td>0.957553</td>\n",
       "      <td>0.962540</td>\n",
       "      <td>10036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.742443</td>\n",
       "      <td>0.792258</td>\n",
       "      <td>0.766542</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.935439</td>\n",
       "      <td>0.935439</td>\n",
       "      <td>0.935439</td>\n",
       "      <td>0.935439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.855011</td>\n",
       "      <td>0.874905</td>\n",
       "      <td>0.864541</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.937460</td>\n",
       "      <td>0.935439</td>\n",
       "      <td>0.936319</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.967580  0.957553  0.962540  10036.000000\n",
       "True           0.742443  0.792258  0.766542   1550.000000\n",
       "accuracy       0.935439  0.935439  0.935439      0.935439\n",
       "macro avg      0.855011  0.874905  0.864541  11586.000000\n",
       "weighted avg   0.937460  0.935439  0.936319  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.971091</td>\n",
       "      <td>0.955710</td>\n",
       "      <td>0.963339</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.701974</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.741487</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.935785</td>\n",
       "      <td>0.935785</td>\n",
       "      <td>0.935785</td>\n",
       "      <td>0.935785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.836532</td>\n",
       "      <td>0.870712</td>\n",
       "      <td>0.852413</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.939547</td>\n",
       "      <td>0.935785</td>\n",
       "      <td>0.937336</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.971091  0.955710  0.963339  10228.000000\n",
       "True           0.701974  0.785714  0.741487   1358.000000\n",
       "accuracy       0.935785  0.935785  0.935785      0.935785\n",
       "macro avg      0.836532  0.870712  0.852413  11586.000000\n",
       "weighted avg   0.939547  0.935785  0.937336  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.971567</td>\n",
       "      <td>0.960847</td>\n",
       "      <td>0.966177</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.724777</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.754016</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.940532</td>\n",
       "      <td>0.940532</td>\n",
       "      <td>0.940532</td>\n",
       "      <td>0.940532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.848172</td>\n",
       "      <td>0.873281</td>\n",
       "      <td>0.860097</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.942939</td>\n",
       "      <td>0.940532</td>\n",
       "      <td>0.941566</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.971567  0.960847  0.966177  10242.000000\n",
       "True           0.724777  0.785714  0.754016   1344.000000\n",
       "accuracy       0.940532  0.940532  0.940532      0.940532\n",
       "macro avg      0.848172  0.873281  0.860097  11586.000000\n",
       "weighted avg   0.942939  0.940532  0.941566  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.974714</td>\n",
       "      <td>0.961757</td>\n",
       "      <td>0.968192</td>\n",
       "      <td>10381.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.704393</td>\n",
       "      <td>0.785062</td>\n",
       "      <td>0.742543</td>\n",
       "      <td>1205.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.943380</td>\n",
       "      <td>0.943380</td>\n",
       "      <td>0.943380</td>\n",
       "      <td>0.94338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.839554</td>\n",
       "      <td>0.873410</td>\n",
       "      <td>0.855368</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.946600</td>\n",
       "      <td>0.943380</td>\n",
       "      <td>0.944724</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.974714  0.961757  0.968192  10381.00000\n",
       "True           0.704393  0.785062  0.742543   1205.00000\n",
       "accuracy       0.943380  0.943380  0.943380      0.94338\n",
       "macro avg      0.839554  0.873410  0.855368  11586.00000\n",
       "weighted avg   0.946600  0.943380  0.944724  11586.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.967247</td>\n",
       "      <td>0.962073</td>\n",
       "      <td>0.964653</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.712813</td>\n",
       "      <td>0.742901</td>\n",
       "      <td>0.727546</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.937424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.840030</td>\n",
       "      <td>0.852487</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.938632</td>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.937987</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.967247  0.962073  0.964653  10283.000000\n",
       "True           0.712813  0.742901  0.727546   1303.000000\n",
       "accuracy       0.937424  0.937424  0.937424      0.937424\n",
       "macro avg      0.840030  0.852487  0.846100  11586.000000\n",
       "weighted avg   0.938632  0.937424  0.937987  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.8395200406366901\n",
      "average recall = 0.867698193010693\n",
      "average f1-score = 0.8527260605683757\n",
      "average support = 11586.4\n",
      "0.9367707052066165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[10111,   424],\n",
       "        [  255,   797]], dtype=int64),\n",
       " array([[9704,  481],\n",
       "        [ 337, 1065]], dtype=int64),\n",
       " array([[9846,  390],\n",
       "        [ 265, 1086]], dtype=int64),\n",
       " array([[9676,  472],\n",
       "        [ 318, 1121]], dtype=int64),\n",
       " array([[9520,  480],\n",
       "        [ 342, 1244]], dtype=int64),\n",
       " array([[9610,  426],\n",
       "        [ 322, 1228]], dtype=int64),\n",
       " array([[9775,  453],\n",
       "        [ 291, 1067]], dtype=int64),\n",
       " array([[9841,  401],\n",
       "        [ 288, 1056]], dtype=int64),\n",
       " array([[9984,  397],\n",
       "        [ 259,  946]], dtype=int64),\n",
       " array([[9893,  390],\n",
       "        [ 335,  968]], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    91739\n",
      "True     91739\n",
      "Name: attack, dtype: int64\n",
      "False    92089\n",
      "True     92089\n",
      "Name: attack, dtype: int64\n",
      "False    92038\n",
      "True     92038\n",
      "Name: attack, dtype: int64\n",
      "False    92126\n",
      "True     92126\n",
      "Name: attack, dtype: int64\n",
      "False    92274\n",
      "True     92274\n",
      "Name: attack, dtype: int64\n",
      "False    92238\n",
      "True     92238\n",
      "Name: attack, dtype: int64\n",
      "False    92046\n",
      "True     92046\n",
      "Name: attack, dtype: int64\n",
      "False    92032\n",
      "True     92032\n",
      "Name: attack, dtype: int64\n",
      "False    91893\n",
      "True     91893\n",
      "Name: attack, dtype: int64\n",
      "False    91991\n",
      "True     91991\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',RidgeClassifier())\n",
    "])\n",
    "score,confusion=kCrossValidation(clf,comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.975504</td>\n",
       "      <td>0.918557</td>\n",
       "      <td>0.946175</td>\n",
       "      <td>10535.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.485303</td>\n",
       "      <td>0.769011</td>\n",
       "      <td>0.595072</td>\n",
       "      <td>1052.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.904980</td>\n",
       "      <td>0.904980</td>\n",
       "      <td>0.904980</td>\n",
       "      <td>0.90498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.730403</td>\n",
       "      <td>0.843784</td>\n",
       "      <td>0.770623</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.930998</td>\n",
       "      <td>0.904980</td>\n",
       "      <td>0.914297</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.975504  0.918557  0.946175  10535.00000\n",
       "True           0.485303  0.769011  0.595072   1052.00000\n",
       "accuracy       0.904980  0.904980  0.904980      0.90498\n",
       "macro avg      0.730403  0.843784  0.770623  11587.00000\n",
       "weighted avg   0.930998  0.904980  0.914297  11587.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.967372</td>\n",
       "      <td>0.911144</td>\n",
       "      <td>0.938416</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.546138</td>\n",
       "      <td>0.776748</td>\n",
       "      <td>0.641343</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.894882</td>\n",
       "      <td>0.894882</td>\n",
       "      <td>0.894882</td>\n",
       "      <td>0.894882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.756755</td>\n",
       "      <td>0.843946</td>\n",
       "      <td>0.789880</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.916404</td>\n",
       "      <td>0.894882</td>\n",
       "      <td>0.902471</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.967372  0.911144  0.938416  10185.000000\n",
       "True           0.546138  0.776748  0.641343   1402.000000\n",
       "accuracy       0.894882  0.894882  0.894882      0.894882\n",
       "macro avg      0.756755  0.843946  0.789880  11587.000000\n",
       "weighted avg   0.916404  0.894882  0.902471  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.972242</td>\n",
       "      <td>0.917057</td>\n",
       "      <td>0.943844</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.560559</td>\n",
       "      <td>0.801628</td>\n",
       "      <td>0.659762</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.903599</td>\n",
       "      <td>0.903599</td>\n",
       "      <td>0.903599</td>\n",
       "      <td>0.903599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.766401</td>\n",
       "      <td>0.859343</td>\n",
       "      <td>0.801803</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.903599</td>\n",
       "      <td>0.910721</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.972242  0.917057  0.943844  10236.000000\n",
       "True           0.560559  0.801628  0.659762   1351.000000\n",
       "accuracy       0.903599  0.903599  0.903599      0.903599\n",
       "macro avg      0.766401  0.859343  0.801803  11587.000000\n",
       "weighted avg   0.924242  0.903599  0.910721  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.966369</td>\n",
       "      <td>0.906090</td>\n",
       "      <td>0.935259</td>\n",
       "      <td>10148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.540058</td>\n",
       "      <td>0.777623</td>\n",
       "      <td>0.637425</td>\n",
       "      <td>1439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.890135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.753213</td>\n",
       "      <td>0.841857</td>\n",
       "      <td>0.786342</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.913425</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.898271</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.966369  0.906090  0.935259  10148.000000\n",
       "True           0.540058  0.777623  0.637425   1439.000000\n",
       "accuracy       0.890135  0.890135  0.890135      0.890135\n",
       "macro avg      0.753213  0.841857  0.786342  11587.000000\n",
       "weighted avg   0.913425  0.890135  0.898271  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.965349</td>\n",
       "      <td>0.908200</td>\n",
       "      <td>0.935903</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.578512</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.669501</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.892629</td>\n",
       "      <td>0.892629</td>\n",
       "      <td>0.892629</td>\n",
       "      <td>0.892629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.771931</td>\n",
       "      <td>0.851326</td>\n",
       "      <td>0.802702</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.912395</td>\n",
       "      <td>0.892629</td>\n",
       "      <td>0.899435</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.965349  0.908200  0.935903  10000.000000\n",
       "True           0.578512  0.794451  0.669501   1586.000000\n",
       "accuracy       0.892629  0.892629  0.892629      0.892629\n",
       "macro avg      0.771931  0.851326  0.802702  11586.000000\n",
       "weighted avg   0.912395  0.892629  0.899435  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.968916</td>\n",
       "      <td>0.910024</td>\n",
       "      <td>0.938547</td>\n",
       "      <td>10036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.810968</td>\n",
       "      <td>0.677628</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.896772</td>\n",
       "      <td>0.896772</td>\n",
       "      <td>0.896772</td>\n",
       "      <td>0.896772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.775430</td>\n",
       "      <td>0.860496</td>\n",
       "      <td>0.808087</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.917146</td>\n",
       "      <td>0.896772</td>\n",
       "      <td>0.903641</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.968916  0.910024  0.938547  10036.000000\n",
       "True           0.581944  0.810968  0.677628   1550.000000\n",
       "accuracy       0.896772  0.896772  0.896772      0.896772\n",
       "macro avg      0.775430  0.860496  0.808087  11586.000000\n",
       "weighted avg   0.917146  0.896772  0.903641  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.973051</td>\n",
       "      <td>0.917873</td>\n",
       "      <td>0.944657</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.566563</td>\n",
       "      <td>0.808542</td>\n",
       "      <td>0.666262</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.905058</td>\n",
       "      <td>0.905058</td>\n",
       "      <td>0.905058</td>\n",
       "      <td>0.905058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.769807</td>\n",
       "      <td>0.863207</td>\n",
       "      <td>0.805460</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.925407</td>\n",
       "      <td>0.905058</td>\n",
       "      <td>0.912026</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.973051  0.917873  0.944657  10228.000000\n",
       "True           0.566563  0.808542  0.666262   1358.000000\n",
       "accuracy       0.905058  0.905058  0.905058      0.905058\n",
       "macro avg      0.769807  0.863207  0.805460  11586.000000\n",
       "weighted avg   0.925407  0.905058  0.912026  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.970806</td>\n",
       "      <td>0.922086</td>\n",
       "      <td>0.945819</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.570506</td>\n",
       "      <td>0.788690</td>\n",
       "      <td>0.662086</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.906611</td>\n",
       "      <td>0.906611</td>\n",
       "      <td>0.906611</td>\n",
       "      <td>0.906611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.770656</td>\n",
       "      <td>0.855388</td>\n",
       "      <td>0.803952</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.906611</td>\n",
       "      <td>0.912905</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.970806  0.922086  0.945819  10242.000000\n",
       "True           0.570506  0.788690  0.662086   1344.000000\n",
       "accuracy       0.906611  0.906611  0.906611      0.906611\n",
       "macro avg      0.770656  0.855388  0.803952  11586.000000\n",
       "weighted avg   0.924370  0.906611  0.912905  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.974369</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.947905</td>\n",
       "      <td>10381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.543330</td>\n",
       "      <td>0.790871</td>\n",
       "      <td>0.644137</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.909114</td>\n",
       "      <td>0.909114</td>\n",
       "      <td>0.909114</td>\n",
       "      <td>0.909114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.758849</td>\n",
       "      <td>0.856856</td>\n",
       "      <td>0.796021</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.929539</td>\n",
       "      <td>0.909114</td>\n",
       "      <td>0.916311</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.974369  0.922840  0.947905  10381.000000\n",
       "True           0.543330  0.790871  0.644137   1205.000000\n",
       "accuracy       0.909114  0.909114  0.909114      0.909114\n",
       "macro avg      0.758849  0.856856  0.796021  11586.000000\n",
       "weighted avg   0.929539  0.909114  0.916311  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.968926</td>\n",
       "      <td>0.921813</td>\n",
       "      <td>0.944782</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.554077</td>\n",
       "      <td>0.766692</td>\n",
       "      <td>0.643271</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.904367</td>\n",
       "      <td>0.904367</td>\n",
       "      <td>0.904367</td>\n",
       "      <td>0.904367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.761501</td>\n",
       "      <td>0.844252</td>\n",
       "      <td>0.794027</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.922270</td>\n",
       "      <td>0.904367</td>\n",
       "      <td>0.910873</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.968926  0.921813  0.944782  10283.000000\n",
       "True           0.554077  0.766692  0.643271   1303.000000\n",
       "accuracy       0.904367  0.904367  0.904367      0.904367\n",
       "macro avg      0.761501  0.844252  0.794027  11586.000000\n",
       "weighted avg   0.922270  0.904367  0.910873  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.7614947366019436\n",
      "average recall = 0.852045437081338\n",
      "average f1-score = 0.7958896460325048\n",
      "average support = 11586.4\n",
      "0.9008148317256026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[9677,  858],\n",
       "        [ 243,  809]], dtype=int64),\n",
       " array([[9280,  905],\n",
       "        [ 313, 1089]], dtype=int64),\n",
       " array([[9387,  849],\n",
       "        [ 268, 1083]], dtype=int64),\n",
       " array([[9195,  953],\n",
       "        [ 320, 1119]], dtype=int64),\n",
       " array([[9082,  918],\n",
       "        [ 326, 1260]], dtype=int64),\n",
       " array([[9133,  903],\n",
       "        [ 293, 1257]], dtype=int64),\n",
       " array([[9388,  840],\n",
       "        [ 260, 1098]], dtype=int64),\n",
       " array([[9444,  798],\n",
       "        [ 284, 1060]], dtype=int64),\n",
       " array([[9580,  801],\n",
       "        [ 252,  953]], dtype=int64),\n",
       " array([[9479,  804],\n",
       "        [ 304,  999]], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    91739\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n",
      "False    92089\n",
      "True     12188\n",
      "Name: attack, dtype: int64\n",
      "False    92038\n",
      "True     12239\n",
      "Name: attack, dtype: int64\n",
      "False    92126\n",
      "True     12151\n",
      "Name: attack, dtype: int64\n",
      "False    92274\n",
      "True     12004\n",
      "Name: attack, dtype: int64\n",
      "False    92238\n",
      "True     12040\n",
      "Name: attack, dtype: int64\n",
      "False    92046\n",
      "True     12232\n",
      "Name: attack, dtype: int64\n",
      "False    92032\n",
      "True     12246\n",
      "Name: attack, dtype: int64\n",
      "False    91893\n",
      "True     12385\n",
      "Name: attack, dtype: int64\n",
      "False    91991\n",
      "True     12287\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',SGDClassifier())\n",
    "])\n",
    "score,confusion=kCrossValidation(clf,comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.946146</td>\n",
       "      <td>0.997247</td>\n",
       "      <td>0.971025</td>\n",
       "      <td>10535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.939959</td>\n",
       "      <td>0.431559</td>\n",
       "      <td>0.591531</td>\n",
       "      <td>1052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.945888</td>\n",
       "      <td>0.945888</td>\n",
       "      <td>0.945888</td>\n",
       "      <td>0.945888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.943052</td>\n",
       "      <td>0.714403</td>\n",
       "      <td>0.781278</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.945584</td>\n",
       "      <td>0.945888</td>\n",
       "      <td>0.936570</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.946146  0.997247  0.971025  10535.000000\n",
       "True           0.939959  0.431559  0.591531   1052.000000\n",
       "accuracy       0.945888  0.945888  0.945888      0.945888\n",
       "macro avg      0.943052  0.714403  0.781278  11587.000000\n",
       "weighted avg   0.945584  0.945888  0.936570  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.929121</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.961478</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.941529</td>\n",
       "      <td>0.447932</td>\n",
       "      <td>0.607057</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.929835</td>\n",
       "      <td>0.929835</td>\n",
       "      <td>0.929835</td>\n",
       "      <td>0.929835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.935325</td>\n",
       "      <td>0.722051</td>\n",
       "      <td>0.784267</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.930622</td>\n",
       "      <td>0.929835</td>\n",
       "      <td>0.918594</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.929121  0.996171  0.961478  10185.000000\n",
       "True           0.941529  0.447932  0.607057   1402.000000\n",
       "accuracy       0.929835  0.929835  0.929835      0.929835\n",
       "macro avg      0.935325  0.722051  0.784267  11587.000000\n",
       "weighted avg   0.930622  0.929835  0.918594  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.996190</td>\n",
       "      <td>0.966815</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.946502</td>\n",
       "      <td>0.510733</td>\n",
       "      <td>0.663462</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939587</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>0.939587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.942813</td>\n",
       "      <td>0.753461</td>\n",
       "      <td>0.815138</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.939984</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>0.931445</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.939123  0.996190  0.966815  10236.000000\n",
       "True           0.946502  0.510733  0.663462   1351.000000\n",
       "accuracy       0.939587  0.939587  0.939587      0.939587\n",
       "macro avg      0.942813  0.753461  0.815138  11587.000000\n",
       "weighted avg   0.939984  0.939587  0.931445  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.928217</td>\n",
       "      <td>0.996453</td>\n",
       "      <td>0.961125</td>\n",
       "      <td>10148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.456567</td>\n",
       "      <td>0.616323</td>\n",
       "      <td>1439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.929404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.938135</td>\n",
       "      <td>0.726510</td>\n",
       "      <td>0.788724</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.930681</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.918304</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.928217  0.996453  0.961125  10148.000000\n",
       "True           0.948052  0.456567  0.616323   1439.000000\n",
       "accuracy       0.929404  0.929404  0.929404      0.929404\n",
       "macro avg      0.938135  0.726510  0.788724  11587.000000\n",
       "weighted avg   0.930681  0.929404  0.918304  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.959552</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.930876</td>\n",
       "      <td>0.509458</td>\n",
       "      <td>0.658517</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.927671</td>\n",
       "      <td>0.927671</td>\n",
       "      <td>0.927671</td>\n",
       "      <td>0.927671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.929144</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>0.809034</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.927886</td>\n",
       "      <td>0.927671</td>\n",
       "      <td>0.918344</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.927412  0.994000  0.959552  10000.000000\n",
       "True           0.930876  0.509458  0.658517   1586.000000\n",
       "accuracy       0.927671  0.927671  0.927671      0.927671\n",
       "macro avg      0.929144  0.751729  0.809034  11586.000000\n",
       "weighted avg   0.927886  0.927671  0.918344  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.928558</td>\n",
       "      <td>0.995915</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>10036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.950122</td>\n",
       "      <td>0.503871</td>\n",
       "      <td>0.658516</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.930088</td>\n",
       "      <td>0.930088</td>\n",
       "      <td>0.930088</td>\n",
       "      <td>0.930088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.939340</td>\n",
       "      <td>0.749893</td>\n",
       "      <td>0.809787</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.931443</td>\n",
       "      <td>0.930088</td>\n",
       "      <td>0.920583</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.928558  0.995915  0.961058  10036.000000\n",
       "True           0.950122  0.503871  0.658516   1550.000000\n",
       "accuracy       0.930088  0.930088  0.930088      0.930088\n",
       "macro avg      0.939340  0.749893  0.809787  11586.000000\n",
       "weighted avg   0.931443  0.930088  0.920583  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.931864</td>\n",
       "      <td>0.996187</td>\n",
       "      <td>0.962952</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.940184</td>\n",
       "      <td>0.451399</td>\n",
       "      <td>0.609950</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.932332</td>\n",
       "      <td>0.932332</td>\n",
       "      <td>0.932332</td>\n",
       "      <td>0.932332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.936024</td>\n",
       "      <td>0.723793</td>\n",
       "      <td>0.786451</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.932839</td>\n",
       "      <td>0.932332</td>\n",
       "      <td>0.921577</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.931864  0.996187  0.962952  10228.000000\n",
       "True           0.940184  0.451399  0.609950   1358.000000\n",
       "accuracy       0.932332  0.932332  0.932332      0.932332\n",
       "macro avg      0.936024  0.723793  0.786451  11586.000000\n",
       "weighted avg   0.932839  0.932332  0.921577  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.933199</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.964078</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.953344</td>\n",
       "      <td>0.456101</td>\n",
       "      <td>0.617011</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.934317</td>\n",
       "      <td>0.934317</td>\n",
       "      <td>0.934317</td>\n",
       "      <td>0.934317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.943272</td>\n",
       "      <td>0.726586</td>\n",
       "      <td>0.790544</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.935536</td>\n",
       "      <td>0.934317</td>\n",
       "      <td>0.923818</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.933199  0.997071  0.964078  10242.000000\n",
       "True           0.953344  0.456101  0.617011   1344.000000\n",
       "accuracy       0.934317  0.934317  0.934317      0.934317\n",
       "macro avg      0.943272  0.726586  0.790544  11586.000000\n",
       "weighted avg   0.935536  0.934317  0.923818  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.996532</td>\n",
       "      <td>0.968270</td>\n",
       "      <td>10381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.939900</td>\n",
       "      <td>0.467220</td>\n",
       "      <td>0.624169</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.941481</td>\n",
       "      <td>0.941481</td>\n",
       "      <td>0.941481</td>\n",
       "      <td>0.941481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.940734</td>\n",
       "      <td>0.731876</td>\n",
       "      <td>0.796219</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.941394</td>\n",
       "      <td>0.941481</td>\n",
       "      <td>0.932482</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.941567  0.996532  0.968270  10381.000000\n",
       "True           0.939900  0.467220  0.624169   1205.000000\n",
       "accuracy       0.941481  0.941481  0.941481      0.941481\n",
       "macro avg      0.940734  0.731876  0.796219  11586.000000\n",
       "weighted avg   0.941394  0.941481  0.932482  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.934562</td>\n",
       "      <td>0.995818</td>\n",
       "      <td>0.964218</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.931638</td>\n",
       "      <td>0.449731</td>\n",
       "      <td>0.606625</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.934404</td>\n",
       "      <td>0.934404</td>\n",
       "      <td>0.934404</td>\n",
       "      <td>0.934404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.933100</td>\n",
       "      <td>0.722775</td>\n",
       "      <td>0.785422</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.934233</td>\n",
       "      <td>0.934404</td>\n",
       "      <td>0.924002</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.934562  0.995818  0.964218  10283.000000\n",
       "True           0.931638  0.449731  0.606625   1303.000000\n",
       "accuracy       0.934404  0.934404  0.934404      0.934404\n",
       "macro avg      0.933100  0.722775  0.785422  11586.000000\n",
       "weighted avg   0.934233  0.934404  0.924002  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.9380937032251833\n",
      "average recall = 0.7323077088277888\n",
      "average f1-score = 0.7946865924338861\n",
      "average support = 11586.4\n",
      "0.9345007361133824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[10506,    29],\n",
       "        [  598,   454]], dtype=int64),\n",
       " array([[10146,    39],\n",
       "        [  774,   628]], dtype=int64),\n",
       " array([[10197,    39],\n",
       "        [  661,   690]], dtype=int64),\n",
       " array([[10112,    36],\n",
       "        [  782,   657]], dtype=int64),\n",
       " array([[9940,   60],\n",
       "        [ 778,  808]], dtype=int64),\n",
       " array([[9995,   41],\n",
       "        [ 769,  781]], dtype=int64),\n",
       " array([[10189,    39],\n",
       "        [  745,   613]], dtype=int64),\n",
       " array([[10212,    30],\n",
       "        [  731,   613]], dtype=int64),\n",
       " array([[10345,    36],\n",
       "        [  642,   563]], dtype=int64),\n",
       " array([[10240,    43],\n",
       "        [  717,   586]], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    91739\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n",
      "False    92089\n",
      "True     12188\n",
      "Name: attack, dtype: int64\n",
      "False    92038\n",
      "True     12239\n",
      "Name: attack, dtype: int64\n",
      "False    92126\n",
      "True     12151\n",
      "Name: attack, dtype: int64\n",
      "False    92274\n",
      "True     12004\n",
      "Name: attack, dtype: int64\n",
      "False    92238\n",
      "True     12040\n",
      "Name: attack, dtype: int64\n",
      "False    92046\n",
      "True     12232\n",
      "Name: attack, dtype: int64\n",
      "False    92032\n",
      "True     12246\n",
      "Name: attack, dtype: int64\n",
      "False    91893\n",
      "True     12385\n",
      "Name: attack, dtype: int64\n",
      "False    91991\n",
      "True     12287\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',SGDClassifier())\n",
    "])\n",
    "score,confusion=kCrossValidation(clf,comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.945990</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.971077</td>\n",
       "      <td>10535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.945607</td>\n",
       "      <td>0.429658</td>\n",
       "      <td>0.590850</td>\n",
       "      <td>1052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.945974</td>\n",
       "      <td>0.945974</td>\n",
       "      <td>0.945974</td>\n",
       "      <td>0.945974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.945798</td>\n",
       "      <td>0.713595</td>\n",
       "      <td>0.780964</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.945955</td>\n",
       "      <td>0.945974</td>\n",
       "      <td>0.936556</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.945990  0.997532  0.971077  10535.000000\n",
       "True           0.945607  0.429658  0.590850   1052.000000\n",
       "accuracy       0.945974  0.945974  0.945974      0.945974\n",
       "macro avg      0.945798  0.713595  0.780964  11587.000000\n",
       "weighted avg   0.945955  0.945974  0.936556  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.929206</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.961524</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.941617</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>0.607729</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.929921</td>\n",
       "      <td>0.929921</td>\n",
       "      <td>0.929921</td>\n",
       "      <td>0.929921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.935411</td>\n",
       "      <td>0.722408</td>\n",
       "      <td>0.784627</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.930708</td>\n",
       "      <td>0.929921</td>\n",
       "      <td>0.918716</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.929206  0.996171  0.961524  10185.000000\n",
       "True           0.941617  0.448645  0.607729   1402.000000\n",
       "accuracy       0.929921  0.929921  0.929921      0.929921\n",
       "macro avg      0.935411  0.722408  0.784627  11587.000000\n",
       "weighted avg   0.930708  0.929921  0.918716  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.938368</td>\n",
       "      <td>0.996581</td>\n",
       "      <td>0.966599</td>\n",
       "      <td>10236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.951117</td>\n",
       "      <td>0.504071</td>\n",
       "      <td>0.658926</td>\n",
       "      <td>1351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939156</td>\n",
       "      <td>0.939156</td>\n",
       "      <td>0.939156</td>\n",
       "      <td>0.939156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.944743</td>\n",
       "      <td>0.750326</td>\n",
       "      <td>0.812762</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.939855</td>\n",
       "      <td>0.939156</td>\n",
       "      <td>0.930725</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.938368  0.996581  0.966599  10236.000000\n",
       "True           0.951117  0.504071  0.658926   1351.000000\n",
       "accuracy       0.939156  0.939156  0.939156      0.939156\n",
       "macro avg      0.944743  0.750326  0.812762  11587.000000\n",
       "weighted avg   0.939855  0.939156  0.930725  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.927877</td>\n",
       "      <td>0.996453</td>\n",
       "      <td>0.960943</td>\n",
       "      <td>10148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.947750</td>\n",
       "      <td>0.453787</td>\n",
       "      <td>0.613722</td>\n",
       "      <td>1439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.929058</td>\n",
       "      <td>0.929058</td>\n",
       "      <td>0.929058</td>\n",
       "      <td>0.929058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.937814</td>\n",
       "      <td>0.725120</td>\n",
       "      <td>0.787332</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.930345</td>\n",
       "      <td>0.929058</td>\n",
       "      <td>0.917821</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.927877  0.996453  0.960943  10148.000000\n",
       "True           0.947750  0.453787  0.613722   1439.000000\n",
       "accuracy       0.929058  0.929058  0.929058      0.929058\n",
       "macro avg      0.937814  0.725120  0.787332  11587.000000\n",
       "weighted avg   0.930345  0.929058  0.917821  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.927166</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>0.959514</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.932793</td>\n",
       "      <td>0.507566</td>\n",
       "      <td>0.657411</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.927585</td>\n",
       "      <td>0.927585</td>\n",
       "      <td>0.927585</td>\n",
       "      <td>0.927585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.929979</td>\n",
       "      <td>0.750883</td>\n",
       "      <td>0.808462</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.927936</td>\n",
       "      <td>0.927585</td>\n",
       "      <td>0.918159</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.927166  0.994200  0.959514  10000.000000\n",
       "True           0.932793  0.507566  0.657411   1586.000000\n",
       "accuracy       0.927585  0.927585  0.927585      0.927585\n",
       "macro avg      0.929979  0.750883  0.808462  11586.000000\n",
       "weighted avg   0.927936  0.927585  0.918159  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.928990</td>\n",
       "      <td>0.995915</td>\n",
       "      <td>0.961289</td>\n",
       "      <td>10036.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.950423</td>\n",
       "      <td>0.507097</td>\n",
       "      <td>0.661338</td>\n",
       "      <td>1550.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.930520</td>\n",
       "      <td>0.930520</td>\n",
       "      <td>0.930520</td>\n",
       "      <td>0.93052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.939706</td>\n",
       "      <td>0.751506</td>\n",
       "      <td>0.811313</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.931857</td>\n",
       "      <td>0.930520</td>\n",
       "      <td>0.921161</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.928990  0.995915  0.961289  10036.00000\n",
       "True           0.950423  0.507097  0.661338   1550.00000\n",
       "accuracy       0.930520  0.930520  0.930520      0.93052\n",
       "macro avg      0.939706  0.751506  0.811313  11586.00000\n",
       "weighted avg   0.931857  0.930520  0.921161  11586.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.932120</td>\n",
       "      <td>0.996187</td>\n",
       "      <td>0.963089</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.940458</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.612022</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.932591</td>\n",
       "      <td>0.932591</td>\n",
       "      <td>0.932591</td>\n",
       "      <td>0.932591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.936289</td>\n",
       "      <td>0.724898</td>\n",
       "      <td>0.787555</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.933097</td>\n",
       "      <td>0.932591</td>\n",
       "      <td>0.921940</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.932120  0.996187  0.963089  10228.000000\n",
       "True           0.940458  0.453608  0.612022   1358.000000\n",
       "accuracy       0.932591  0.932591  0.932591      0.932591\n",
       "macro avg      0.936289  0.724898  0.787555  11586.000000\n",
       "weighted avg   0.933097  0.932591  0.921940  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.933547</td>\n",
       "      <td>0.997169</td>\n",
       "      <td>0.964309</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.955108</td>\n",
       "      <td>0.459077</td>\n",
       "      <td>0.620101</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.934749</td>\n",
       "      <td>0.934749</td>\n",
       "      <td>0.934749</td>\n",
       "      <td>0.934749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.944327</td>\n",
       "      <td>0.728123</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.936048</td>\n",
       "      <td>0.934749</td>\n",
       "      <td>0.924380</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.933547  0.997169  0.964309  10242.000000\n",
       "True           0.955108  0.459077  0.620101   1344.000000\n",
       "accuracy       0.934749  0.934749  0.934749      0.934749\n",
       "macro avg      0.944327  0.728123  0.792205  11586.000000\n",
       "weighted avg   0.936048  0.934749  0.924380  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.941814</td>\n",
       "      <td>0.996339</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>10381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.937086</td>\n",
       "      <td>0.469710</td>\n",
       "      <td>0.625760</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.941567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.939450</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>0.797035</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.941322</td>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.932683</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.941814  0.996339  0.968310  10381.000000\n",
       "True           0.937086  0.469710  0.625760   1205.000000\n",
       "accuracy       0.941567  0.941567  0.941567      0.941567\n",
       "macro avg      0.939450  0.733025  0.797035  11586.000000\n",
       "weighted avg   0.941322  0.941567  0.932683  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.934648</td>\n",
       "      <td>0.995818</td>\n",
       "      <td>0.964264</td>\n",
       "      <td>10283.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.931746</td>\n",
       "      <td>0.450499</td>\n",
       "      <td>0.607346</td>\n",
       "      <td>1303.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.934490</td>\n",
       "      <td>0.934490</td>\n",
       "      <td>0.934490</td>\n",
       "      <td>0.93449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.933197</td>\n",
       "      <td>0.723159</td>\n",
       "      <td>0.785805</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.934321</td>\n",
       "      <td>0.934490</td>\n",
       "      <td>0.924124</td>\n",
       "      <td>11586.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.934648  0.995818  0.964264  10283.00000\n",
       "True           0.931746  0.450499  0.607346   1303.00000\n",
       "accuracy       0.934490  0.934490  0.934490      0.93449\n",
       "macro avg      0.933197  0.723159  0.785805  11586.00000\n",
       "weighted avg   0.934321  0.934490  0.924124  11586.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.9386714692775486\n",
      "average recall = 0.7323041022938724\n",
      "average f1-score = 0.7948060733115108\n",
      "average support = 11586.4\n",
      "0.9345611590732072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[10509,    26],\n",
       "        [  600,   452]], dtype=int64),\n",
       " array([[10146,    39],\n",
       "        [  773,   629]], dtype=int64),\n",
       " array([[10201,    35],\n",
       "        [  670,   681]], dtype=int64),\n",
       " array([[10112,    36],\n",
       "        [  786,   653]], dtype=int64),\n",
       " array([[9942,   58],\n",
       "        [ 781,  805]], dtype=int64),\n",
       " array([[9995,   41],\n",
       "        [ 764,  786]], dtype=int64),\n",
       " array([[10189,    39],\n",
       "        [  742,   616]], dtype=int64),\n",
       " array([[10213,    29],\n",
       "        [  727,   617]], dtype=int64),\n",
       " array([[10343,    38],\n",
       "        [  639,   566]], dtype=int64),\n",
       " array([[10240,    43],\n",
       "        [  716,   587]], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "False    91739\n",
      "True     12538\n",
      "Name: attack, dtype: int64\n",
      "False    92089\n",
      "True     12188\n",
      "Name: attack, dtype: int64\n",
      "False    92038\n",
      "True     12239\n",
      "Name: attack, dtype: int64\n",
      "False    92126\n",
      "True     12151\n",
      "Name: attack, dtype: int64\n",
      "False    92274\n",
      "True     12004\n",
      "Name: attack, dtype: int64\n",
      "False    92238\n",
      "True     12040\n",
      "Name: attack, dtype: int64\n",
      "False    92046\n",
      "True     12232\n",
      "Name: attack, dtype: int64\n",
      "False    92032\n",
      "True     12246\n",
      "Name: attack, dtype: int64\n",
      "False    91893\n",
      "True     12385\n",
      "Name: attack, dtype: int64\n",
      "False    91991\n",
      "True     12287\n",
      "Name: attack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',Perceptron())\n",
    "])\n",
    "score,confusion=kCrossValidation(clf,comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.963342</td>\n",
       "      <td>0.955387</td>\n",
       "      <td>0.959348</td>\n",
       "      <td>10535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.587357</td>\n",
       "      <td>0.635932</td>\n",
       "      <td>0.610680</td>\n",
       "      <td>1052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.926383</td>\n",
       "      <td>0.926383</td>\n",
       "      <td>0.926383</td>\n",
       "      <td>0.926383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.795659</td>\n",
       "      <td>0.785014</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.929206</td>\n",
       "      <td>0.926383</td>\n",
       "      <td>0.927692</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.963342  0.955387  0.959348  10535.000000\n",
       "True           0.587357  0.635932  0.610680   1052.000000\n",
       "accuracy       0.926383  0.926383  0.926383      0.926383\n",
       "macro avg      0.775350  0.795659  0.785014  11587.000000\n",
       "weighted avg   0.929206  0.926383  0.927692  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.948646</td>\n",
       "      <td>0.959450</td>\n",
       "      <td>0.954017</td>\n",
       "      <td>10185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.678849</td>\n",
       "      <td>0.622682</td>\n",
       "      <td>0.649554</td>\n",
       "      <td>1402.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.918702</td>\n",
       "      <td>0.918702</td>\n",
       "      <td>0.918702</td>\n",
       "      <td>0.918702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.813747</td>\n",
       "      <td>0.791066</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.916001</td>\n",
       "      <td>0.918702</td>\n",
       "      <td>0.917178</td>\n",
       "      <td>11587.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.948646  0.959450  0.954017  10185.000000\n",
       "True           0.678849  0.622682  0.649554   1402.000000\n",
       "accuracy       0.918702  0.918702  0.918702      0.918702\n",
       "macro avg      0.813747  0.791066  0.801785  11587.000000\n",
       "weighted avg   0.916001  0.918702  0.917178  11587.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.961140</td>\n",
       "      <td>0.961704</td>\n",
       "      <td>0.961422</td>\n",
       "      <td>10236.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.708550</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.706973</td>\n",
       "      <td>1351.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.93182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.834845</td>\n",
       "      <td>0.833554</td>\n",
       "      <td>0.834198</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.931689</td>\n",
       "      <td>0.931820</td>\n",
       "      <td>0.931754</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.961140  0.961704  0.961422  10236.00000\n",
       "True           0.708550  0.705403  0.706973   1351.00000\n",
       "accuracy       0.931820  0.931820  0.931820      0.93182\n",
       "macro avg      0.834845  0.833554  0.834198  11587.00000\n",
       "weighted avg   0.931689  0.931820  0.931754  11587.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.947271</td>\n",
       "      <td>0.961273</td>\n",
       "      <td>0.954221</td>\n",
       "      <td>10148.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.695112</td>\n",
       "      <td>0.622655</td>\n",
       "      <td>0.656891</td>\n",
       "      <td>1439.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.91922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.791964</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.915955</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.917295</td>\n",
       "      <td>11587.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "False          0.947271  0.961273  0.954221  10148.00000\n",
       "True           0.695112  0.622655  0.656891   1439.00000\n",
       "accuracy       0.919220  0.919220  0.919220      0.91922\n",
       "macro avg      0.821192  0.791964  0.805556  11587.00000\n",
       "weighted avg   0.915955  0.919220  0.917295  11587.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.950772</td>\n",
       "      <td>0.954100</td>\n",
       "      <td>0.952433</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.704062</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.696207</td>\n",
       "      <td>1586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.827417</td>\n",
       "      <td>0.821312</td>\n",
       "      <td>0.824320</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.917000</td>\n",
       "      <td>0.917746</td>\n",
       "      <td>0.917359</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.950772  0.954100  0.952433  10000.000000\n",
       "True           0.704062  0.688525  0.696207   1586.000000\n",
       "accuracy       0.917746  0.917746  0.917746      0.917746\n",
       "macro avg      0.827417  0.821312  0.824320  11586.000000\n",
       "weighted avg   0.917000  0.917746  0.917359  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.955321</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>0.951690</td>\n",
       "      <td>10036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.679582</td>\n",
       "      <td>0.712903</td>\n",
       "      <td>0.695844</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.916624</td>\n",
       "      <td>0.916624</td>\n",
       "      <td>0.916624</td>\n",
       "      <td>0.916624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.830495</td>\n",
       "      <td>0.823767</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.918432</td>\n",
       "      <td>0.916624</td>\n",
       "      <td>0.917463</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.955321  0.948087  0.951690  10036.000000\n",
       "True           0.679582  0.712903  0.695844   1550.000000\n",
       "accuracy       0.916624  0.916624  0.916624      0.916624\n",
       "macro avg      0.817452  0.830495  0.823767  11586.000000\n",
       "weighted avg   0.918432  0.916624  0.917463  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.956590</td>\n",
       "      <td>0.954439</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>10228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.662563</td>\n",
       "      <td>0.673785</td>\n",
       "      <td>0.668127</td>\n",
       "      <td>1358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.921543</td>\n",
       "      <td>0.921543</td>\n",
       "      <td>0.921543</td>\n",
       "      <td>0.921543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.809577</td>\n",
       "      <td>0.814112</td>\n",
       "      <td>0.811820</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.922127</td>\n",
       "      <td>0.921543</td>\n",
       "      <td>0.921828</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.956590  0.954439  0.955513  10228.000000\n",
       "True           0.662563  0.673785  0.668127   1358.000000\n",
       "accuracy       0.921543  0.921543  0.921543      0.921543\n",
       "macro avg      0.809577  0.814112  0.811820  11586.000000\n",
       "weighted avg   0.922127  0.921543  0.921828  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.960296</td>\n",
       "      <td>0.951670</td>\n",
       "      <td>0.955963</td>\n",
       "      <td>10242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.655292</td>\n",
       "      <td>0.700149</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.922493</td>\n",
       "      <td>0.922493</td>\n",
       "      <td>0.922493</td>\n",
       "      <td>0.922493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.807794</td>\n",
       "      <td>0.825909</td>\n",
       "      <td>0.816471</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.924915</td>\n",
       "      <td>0.922493</td>\n",
       "      <td>0.923600</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.960296  0.951670  0.955963  10242.000000\n",
       "True           0.655292  0.700149  0.676978   1344.000000\n",
       "accuracy       0.922493  0.922493  0.922493      0.922493\n",
       "macro avg      0.807794  0.825909  0.816471  11586.000000\n",
       "weighted avg   0.924915  0.922493  0.923600  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.964188</td>\n",
       "      <td>0.951835</td>\n",
       "      <td>0.957972</td>\n",
       "      <td>10381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.626308</td>\n",
       "      <td>0.695436</td>\n",
       "      <td>0.659064</td>\n",
       "      <td>1205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.925168</td>\n",
       "      <td>0.925168</td>\n",
       "      <td>0.925168</td>\n",
       "      <td>0.925168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.795248</td>\n",
       "      <td>0.823635</td>\n",
       "      <td>0.808518</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.929047</td>\n",
       "      <td>0.925168</td>\n",
       "      <td>0.926884</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.964188  0.951835  0.957972  10381.000000\n",
       "True           0.626308  0.695436  0.659064   1205.000000\n",
       "accuracy       0.925168  0.925168  0.925168      0.925168\n",
       "macro avg      0.795248  0.823635  0.808518  11586.000000\n",
       "weighted avg   0.929047  0.925168  0.926884  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.953158</td>\n",
       "      <td>0.965671</td>\n",
       "      <td>0.959374</td>\n",
       "      <td>10283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.697774</td>\n",
       "      <td>0.625480</td>\n",
       "      <td>0.659652</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.927412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.825466</td>\n",
       "      <td>0.795576</td>\n",
       "      <td>0.809513</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.924437</td>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.925666</td>\n",
       "      <td>11586.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "False          0.953158  0.965671  0.959374  10283.000000\n",
       "True           0.697774  0.625480  0.659652   1303.000000\n",
       "accuracy       0.927412  0.927412  0.927412      0.927412\n",
       "macro avg      0.825466  0.795576  0.809513  11586.000000\n",
       "weighted avg   0.924437  0.927412  0.925666  11586.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision = 0.8128087754345825\n",
      "average recall = 0.8123282101210695\n",
      "average f1-score = 0.8120962112904501\n",
      "average support = 11586.4\n",
      "0.9227110639999342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[10065,   470],\n",
       "        [  383,   669]], dtype=int64),\n",
       " array([[9772,  413],\n",
       "        [ 529,  873]], dtype=int64),\n",
       " array([[9844,  392],\n",
       "        [ 398,  953]], dtype=int64),\n",
       " array([[9755,  393],\n",
       "        [ 543,  896]], dtype=int64),\n",
       " array([[9541,  459],\n",
       "        [ 494, 1092]], dtype=int64),\n",
       " array([[9515,  521],\n",
       "        [ 445, 1105]], dtype=int64),\n",
       " array([[9762,  466],\n",
       "        [ 443,  915]], dtype=int64),\n",
       " array([[9747,  495],\n",
       "        [ 403,  941]], dtype=int64),\n",
       " array([[9881,  500],\n",
       "        [ 367,  838]], dtype=int64),\n",
       " array([[9930,  353],\n",
       "        [ 488,  815]], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20208/1551795446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m ])\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_comments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_comments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attack'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#score,confusion=kCrossValidation(clf,comments)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             libsvm_sparse.libsvm_sparse_train(\n\u001b[0m\u001b[0;32m    302\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[0mkernel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;34m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',SVC())\n",
    "])\n",
    "clf.fit(train_comments['comment'],train_comments['attack'])\n",
    "#score,confusion=kCrossValidation(clf,comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAverage(score,'macro avg')\n",
    "getAccuracyAverage(score)\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Best R^2 Score : 0.86  Best Params :  {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 3}, 'clf__loss': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=comments['comment']\n",
    "Y=comments['attack']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=12)\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',LinearSVC())\n",
    "])\n",
    "#score,confusion=kCrossValidation(clf,comments)\n",
    "parameter={\n",
    "    'clf__class_weight':[{False:1,True:1},{False:1,True:2},{False:1,True:3}],\n",
    "    #'clf__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'clf__C':[0.1, 1, 10, 100, 1000],\n",
    "    'clf__loss':['hinge', 'squared_hinge']\n",
    "}\n",
    "'''grid = GridSearchCV(clf,\n",
    "                    'clf__param_grid' :{#'max_depth': [None, 2,3,5], 'max_features' : ['auto','sqrt', 'log2'], 'n_estimators': [10,100],\n",
    "                                  'class_weight':[{False:1,True:1},{False:1,True:2},{False:1,True:5},'balanced',{False:1,True:10}]},\n",
    "                    #cv = ShuffleSplit(n_splits=5, random_state=123),\n",
    "                    'clf__scoring':'f1_macro',\n",
    "                    'clf__verbose':50,\n",
    "                    'clf__n_jobs':-1)\n",
    "'''\n",
    "grid=GridSearchCV(clf,param_grid=parameter,scoring='f1_macro',verbose=50,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "print('\\nBest R^2 Score : %.2f'%grid.best_score_, ' Best Params : ', str(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <th>param_clf__loss</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.900869</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>11.561542</td>\n",
       "      <td>0.341576</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.784505</td>\n",
       "      <td>0.782366</td>\n",
       "      <td>0.791861</td>\n",
       "      <td>0.777997</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.783515</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.996718</td>\n",
       "      <td>0.694139</td>\n",
       "      <td>11.367449</td>\n",
       "      <td>0.329186</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.836798</td>\n",
       "      <td>0.834075</td>\n",
       "      <td>0.838263</td>\n",
       "      <td>0.819739</td>\n",
       "      <td>0.835898</td>\n",
       "      <td>0.832955</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.202368</td>\n",
       "      <td>0.943236</td>\n",
       "      <td>11.385968</td>\n",
       "      <td>0.512515</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.842626</td>\n",
       "      <td>0.841724</td>\n",
       "      <td>0.845727</td>\n",
       "      <td>0.831094</td>\n",
       "      <td>0.845059</td>\n",
       "      <td>0.841246</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.176140</td>\n",
       "      <td>0.481584</td>\n",
       "      <td>11.238317</td>\n",
       "      <td>0.163256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.863295</td>\n",
       "      <td>0.858670</td>\n",
       "      <td>0.862186</td>\n",
       "      <td>0.850970</td>\n",
       "      <td>0.856212</td>\n",
       "      <td>0.858267</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.687917</td>\n",
       "      <td>0.950058</td>\n",
       "      <td>11.301657</td>\n",
       "      <td>0.155910</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.859167</td>\n",
       "      <td>0.858839</td>\n",
       "      <td>0.845717</td>\n",
       "      <td>0.857753</td>\n",
       "      <td>0.856492</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76.841673</td>\n",
       "      <td>0.534814</td>\n",
       "      <td>11.343727</td>\n",
       "      <td>0.333566</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.861689</td>\n",
       "      <td>0.861651</td>\n",
       "      <td>0.862823</td>\n",
       "      <td>0.847303</td>\n",
       "      <td>0.858675</td>\n",
       "      <td>0.858428</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82.493756</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>11.221940</td>\n",
       "      <td>0.381159</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, ...</td>\n",
       "      <td>0.847116</td>\n",
       "      <td>0.843653</td>\n",
       "      <td>0.851226</td>\n",
       "      <td>0.836617</td>\n",
       "      <td>0.850808</td>\n",
       "      <td>0.845884</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77.282180</td>\n",
       "      <td>0.442375</td>\n",
       "      <td>11.212339</td>\n",
       "      <td>0.174499</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, ...</td>\n",
       "      <td>0.852449</td>\n",
       "      <td>0.851782</td>\n",
       "      <td>0.853127</td>\n",
       "      <td>0.841563</td>\n",
       "      <td>0.849060</td>\n",
       "      <td>0.849596</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84.561451</td>\n",
       "      <td>0.484929</td>\n",
       "      <td>11.702455</td>\n",
       "      <td>0.224008</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, ...</td>\n",
       "      <td>0.859067</td>\n",
       "      <td>0.859944</td>\n",
       "      <td>0.862191</td>\n",
       "      <td>0.851098</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.858029</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80.898594</td>\n",
       "      <td>0.607979</td>\n",
       "      <td>11.782105</td>\n",
       "      <td>0.475801</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, ...</td>\n",
       "      <td>0.854829</td>\n",
       "      <td>0.852667</td>\n",
       "      <td>0.852698</td>\n",
       "      <td>0.840916</td>\n",
       "      <td>0.847911</td>\n",
       "      <td>0.849804</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>84.815480</td>\n",
       "      <td>1.081417</td>\n",
       "      <td>11.294750</td>\n",
       "      <td>0.108993</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, ...</td>\n",
       "      <td>0.857016</td>\n",
       "      <td>0.858039</td>\n",
       "      <td>0.857984</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.851158</td>\n",
       "      <td>0.853603</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>81.750136</td>\n",
       "      <td>0.428573</td>\n",
       "      <td>11.541969</td>\n",
       "      <td>0.299936</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, ...</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.846216</td>\n",
       "      <td>0.844894</td>\n",
       "      <td>0.830540</td>\n",
       "      <td>0.840789</td>\n",
       "      <td>0.841923</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>91.133001</td>\n",
       "      <td>0.315258</td>\n",
       "      <td>11.980374</td>\n",
       "      <td>0.665553</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1,...</td>\n",
       "      <td>0.843571</td>\n",
       "      <td>0.843607</td>\n",
       "      <td>0.844239</td>\n",
       "      <td>0.827072</td>\n",
       "      <td>0.839887</td>\n",
       "      <td>0.839675</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>94.492686</td>\n",
       "      <td>3.005620</td>\n",
       "      <td>12.511937</td>\n",
       "      <td>0.563878</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1,...</td>\n",
       "      <td>0.832398</td>\n",
       "      <td>0.828442</td>\n",
       "      <td>0.831350</td>\n",
       "      <td>0.813115</td>\n",
       "      <td>0.822229</td>\n",
       "      <td>0.825507</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>94.440113</td>\n",
       "      <td>0.490783</td>\n",
       "      <td>11.612416</td>\n",
       "      <td>0.305617</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1,...</td>\n",
       "      <td>0.839328</td>\n",
       "      <td>0.835065</td>\n",
       "      <td>0.834651</td>\n",
       "      <td>0.816682</td>\n",
       "      <td>0.826022</td>\n",
       "      <td>0.830350</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>109.582534</td>\n",
       "      <td>2.472463</td>\n",
       "      <td>11.818908</td>\n",
       "      <td>0.438377</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1,...</td>\n",
       "      <td>0.823125</td>\n",
       "      <td>0.818756</td>\n",
       "      <td>0.816737</td>\n",
       "      <td>0.801334</td>\n",
       "      <td>0.811319</td>\n",
       "      <td>0.814254</td>\n",
       "      <td>0.007492</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>92.836104</td>\n",
       "      <td>5.172987</td>\n",
       "      <td>11.453452</td>\n",
       "      <td>0.449572</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1,...</td>\n",
       "      <td>0.826747</td>\n",
       "      <td>0.825701</td>\n",
       "      <td>0.828638</td>\n",
       "      <td>0.805736</td>\n",
       "      <td>0.816674</td>\n",
       "      <td>0.820699</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>103.026388</td>\n",
       "      <td>4.140695</td>\n",
       "      <td>11.431197</td>\n",
       "      <td>0.487459</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1,...</td>\n",
       "      <td>0.813667</td>\n",
       "      <td>0.812280</td>\n",
       "      <td>0.810539</td>\n",
       "      <td>0.797958</td>\n",
       "      <td>0.804023</td>\n",
       "      <td>0.807693</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>101.504150</td>\n",
       "      <td>1.827069</td>\n",
       "      <td>11.956911</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.805151</td>\n",
       "      <td>0.803002</td>\n",
       "      <td>0.802251</td>\n",
       "      <td>0.789210</td>\n",
       "      <td>0.801388</td>\n",
       "      <td>0.800200</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>103.797069</td>\n",
       "      <td>6.404548</td>\n",
       "      <td>7.333102</td>\n",
       "      <td>1.950074</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.797295</td>\n",
       "      <td>0.794792</td>\n",
       "      <td>0.796034</td>\n",
       "      <td>0.775275</td>\n",
       "      <td>0.790724</td>\n",
       "      <td>0.790824</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55.129130</td>\n",
       "      <td>1.693662</td>\n",
       "      <td>6.218975</td>\n",
       "      <td>0.351708</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.800689</td>\n",
       "      <td>0.797280</td>\n",
       "      <td>0.801999</td>\n",
       "      <td>0.785495</td>\n",
       "      <td>0.791953</td>\n",
       "      <td>0.795483</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>61.313533</td>\n",
       "      <td>1.457747</td>\n",
       "      <td>5.815066</td>\n",
       "      <td>0.234159</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.790977</td>\n",
       "      <td>0.789309</td>\n",
       "      <td>0.787293</td>\n",
       "      <td>0.773025</td>\n",
       "      <td>0.781326</td>\n",
       "      <td>0.784386</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55.511730</td>\n",
       "      <td>1.411433</td>\n",
       "      <td>5.586064</td>\n",
       "      <td>0.346969</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.794558</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>0.794074</td>\n",
       "      <td>0.780819</td>\n",
       "      <td>0.789515</td>\n",
       "      <td>0.790571</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>62.857365</td>\n",
       "      <td>0.942357</td>\n",
       "      <td>5.498453</td>\n",
       "      <td>0.266728</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1...</td>\n",
       "      <td>0.785942</td>\n",
       "      <td>0.785719</td>\n",
       "      <td>0.784360</td>\n",
       "      <td>0.770505</td>\n",
       "      <td>0.779268</td>\n",
       "      <td>0.781159</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45.355012</td>\n",
       "      <td>2.673739</td>\n",
       "      <td>4.432389</td>\n",
       "      <td>0.351364</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: ...</td>\n",
       "      <td>0.781196</td>\n",
       "      <td>0.767802</td>\n",
       "      <td>0.769024</td>\n",
       "      <td>0.771289</td>\n",
       "      <td>0.766956</td>\n",
       "      <td>0.771253</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>46.739428</td>\n",
       "      <td>0.387943</td>\n",
       "      <td>4.585040</td>\n",
       "      <td>0.229716</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: ...</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.779036</td>\n",
       "      <td>0.770820</td>\n",
       "      <td>0.768193</td>\n",
       "      <td>0.767502</td>\n",
       "      <td>0.773694</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>45.569310</td>\n",
       "      <td>1.331385</td>\n",
       "      <td>4.349390</td>\n",
       "      <td>0.062811</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: ...</td>\n",
       "      <td>0.781458</td>\n",
       "      <td>0.786136</td>\n",
       "      <td>0.775112</td>\n",
       "      <td>0.767849</td>\n",
       "      <td>0.768363</td>\n",
       "      <td>0.775784</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46.808463</td>\n",
       "      <td>0.427383</td>\n",
       "      <td>4.554502</td>\n",
       "      <td>0.168761</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: ...</td>\n",
       "      <td>0.762659</td>\n",
       "      <td>0.773225</td>\n",
       "      <td>0.774547</td>\n",
       "      <td>0.773852</td>\n",
       "      <td>0.763270</td>\n",
       "      <td>0.769511</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>45.624478</td>\n",
       "      <td>0.849445</td>\n",
       "      <td>4.620896</td>\n",
       "      <td>0.314398</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: ...</td>\n",
       "      <td>0.782249</td>\n",
       "      <td>0.770983</td>\n",
       "      <td>0.774963</td>\n",
       "      <td>0.766821</td>\n",
       "      <td>0.773811</td>\n",
       "      <td>0.773765</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>44.262651</td>\n",
       "      <td>5.104208</td>\n",
       "      <td>3.996343</td>\n",
       "      <td>0.900899</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: ...</td>\n",
       "      <td>0.785271</td>\n",
       "      <td>0.774243</td>\n",
       "      <td>0.780715</td>\n",
       "      <td>0.762326</td>\n",
       "      <td>0.776076</td>\n",
       "      <td>0.775726</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
       "0       77.900869      0.505051        11.561542        0.341576          0.1   \n",
       "1       77.996718      0.694139        11.367449        0.329186          0.1   \n",
       "2       78.202368      0.943236        11.385968        0.512515          0.1   \n",
       "3       77.176140      0.481584        11.238317        0.163256          0.1   \n",
       "4       79.687917      0.950058        11.301657        0.155910          0.1   \n",
       "5       76.841673      0.534814        11.343727        0.333566          0.1   \n",
       "6       82.493756      0.518750        11.221940        0.381159            1   \n",
       "7       77.282180      0.442375        11.212339        0.174499            1   \n",
       "8       84.561451      0.484929        11.702455        0.224008            1   \n",
       "9       80.898594      0.607979        11.782105        0.475801            1   \n",
       "10      84.815480      1.081417        11.294750        0.108993            1   \n",
       "11      81.750136      0.428573        11.541969        0.299936            1   \n",
       "12      91.133001      0.315258        11.980374        0.665553           10   \n",
       "13      94.492686      3.005620        12.511937        0.563878           10   \n",
       "14      94.440113      0.490783        11.612416        0.305617           10   \n",
       "15     109.582534      2.472463        11.818908        0.438377           10   \n",
       "16      92.836104      5.172987        11.453452        0.449572           10   \n",
       "17     103.026388      4.140695        11.431197        0.487459           10   \n",
       "18     101.504150      1.827069        11.956911        0.791991          100   \n",
       "19     103.797069      6.404548         7.333102        1.950074          100   \n",
       "20      55.129130      1.693662         6.218975        0.351708          100   \n",
       "21      61.313533      1.457747         5.815066        0.234159          100   \n",
       "22      55.511730      1.411433         5.586064        0.346969          100   \n",
       "23      62.857365      0.942357         5.498453        0.266728          100   \n",
       "24      45.355012      2.673739         4.432389        0.351364         1000   \n",
       "25      46.739428      0.387943         4.585040        0.229716         1000   \n",
       "26      45.569310      1.331385         4.349390        0.062811         1000   \n",
       "27      46.808463      0.427383         4.554502        0.168761         1000   \n",
       "28      45.624478      0.849445         4.620896        0.314398         1000   \n",
       "29      44.262651      5.104208         3.996343        0.900899         1000   \n",
       "\n",
       "   param_clf__class_weight param_clf__loss  \\\n",
       "0      {False: 1, True: 1}           hinge   \n",
       "1      {False: 1, True: 1}   squared_hinge   \n",
       "2      {False: 1, True: 2}           hinge   \n",
       "3      {False: 1, True: 2}   squared_hinge   \n",
       "4      {False: 1, True: 3}           hinge   \n",
       "5      {False: 1, True: 3}   squared_hinge   \n",
       "6      {False: 1, True: 1}           hinge   \n",
       "7      {False: 1, True: 1}   squared_hinge   \n",
       "8      {False: 1, True: 2}           hinge   \n",
       "9      {False: 1, True: 2}   squared_hinge   \n",
       "10     {False: 1, True: 3}           hinge   \n",
       "11     {False: 1, True: 3}   squared_hinge   \n",
       "12     {False: 1, True: 1}           hinge   \n",
       "13     {False: 1, True: 1}   squared_hinge   \n",
       "14     {False: 1, True: 2}           hinge   \n",
       "15     {False: 1, True: 2}   squared_hinge   \n",
       "16     {False: 1, True: 3}           hinge   \n",
       "17     {False: 1, True: 3}   squared_hinge   \n",
       "18     {False: 1, True: 1}           hinge   \n",
       "19     {False: 1, True: 1}   squared_hinge   \n",
       "20     {False: 1, True: 2}           hinge   \n",
       "21     {False: 1, True: 2}   squared_hinge   \n",
       "22     {False: 1, True: 3}           hinge   \n",
       "23     {False: 1, True: 3}   squared_hinge   \n",
       "24     {False: 1, True: 1}           hinge   \n",
       "25     {False: 1, True: 1}   squared_hinge   \n",
       "26     {False: 1, True: 2}           hinge   \n",
       "27     {False: 1, True: 2}   squared_hinge   \n",
       "28     {False: 1, True: 3}           hinge   \n",
       "29     {False: 1, True: 3}   squared_hinge   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'clf__C': 0.1, 'clf__class_weight': {False: 1...           0.784505   \n",
       "1   {'clf__C': 0.1, 'clf__class_weight': {False: 1...           0.836798   \n",
       "2   {'clf__C': 0.1, 'clf__class_weight': {False: 1...           0.842626   \n",
       "3   {'clf__C': 0.1, 'clf__class_weight': {False: 1...           0.863295   \n",
       "4   {'clf__C': 0.1, 'clf__class_weight': {False: 1...           0.860983   \n",
       "5   {'clf__C': 0.1, 'clf__class_weight': {False: 1...           0.861689   \n",
       "6   {'clf__C': 1, 'clf__class_weight': {False: 1, ...           0.847116   \n",
       "7   {'clf__C': 1, 'clf__class_weight': {False: 1, ...           0.852449   \n",
       "8   {'clf__C': 1, 'clf__class_weight': {False: 1, ...           0.859067   \n",
       "9   {'clf__C': 1, 'clf__class_weight': {False: 1, ...           0.854829   \n",
       "10  {'clf__C': 1, 'clf__class_weight': {False: 1, ...           0.857016   \n",
       "11  {'clf__C': 1, 'clf__class_weight': {False: 1, ...           0.847174   \n",
       "12  {'clf__C': 10, 'clf__class_weight': {False: 1,...           0.843571   \n",
       "13  {'clf__C': 10, 'clf__class_weight': {False: 1,...           0.832398   \n",
       "14  {'clf__C': 10, 'clf__class_weight': {False: 1,...           0.839328   \n",
       "15  {'clf__C': 10, 'clf__class_weight': {False: 1,...           0.823125   \n",
       "16  {'clf__C': 10, 'clf__class_weight': {False: 1,...           0.826747   \n",
       "17  {'clf__C': 10, 'clf__class_weight': {False: 1,...           0.813667   \n",
       "18  {'clf__C': 100, 'clf__class_weight': {False: 1...           0.805151   \n",
       "19  {'clf__C': 100, 'clf__class_weight': {False: 1...           0.797295   \n",
       "20  {'clf__C': 100, 'clf__class_weight': {False: 1...           0.800689   \n",
       "21  {'clf__C': 100, 'clf__class_weight': {False: 1...           0.790977   \n",
       "22  {'clf__C': 100, 'clf__class_weight': {False: 1...           0.794558   \n",
       "23  {'clf__C': 100, 'clf__class_weight': {False: 1...           0.785942   \n",
       "24  {'clf__C': 1000, 'clf__class_weight': {False: ...           0.781196   \n",
       "25  {'clf__C': 1000, 'clf__class_weight': {False: ...           0.782918   \n",
       "26  {'clf__C': 1000, 'clf__class_weight': {False: ...           0.781458   \n",
       "27  {'clf__C': 1000, 'clf__class_weight': {False: ...           0.762659   \n",
       "28  {'clf__C': 1000, 'clf__class_weight': {False: ...           0.782249   \n",
       "29  {'clf__C': 1000, 'clf__class_weight': {False: ...           0.785271   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.782366           0.791861           0.777997   \n",
       "1            0.834075           0.838263           0.819739   \n",
       "2            0.841724           0.845727           0.831094   \n",
       "3            0.858670           0.862186           0.850970   \n",
       "4            0.859167           0.858839           0.845717   \n",
       "5            0.861651           0.862823           0.847303   \n",
       "6            0.843653           0.851226           0.836617   \n",
       "7            0.851782           0.853127           0.841563   \n",
       "8            0.859944           0.862191           0.851098   \n",
       "9            0.852667           0.852698           0.840916   \n",
       "10           0.858039           0.857984           0.843819   \n",
       "11           0.846216           0.844894           0.830540   \n",
       "12           0.843607           0.844239           0.827072   \n",
       "13           0.828442           0.831350           0.813115   \n",
       "14           0.835065           0.834651           0.816682   \n",
       "15           0.818756           0.816737           0.801334   \n",
       "16           0.825701           0.828638           0.805736   \n",
       "17           0.812280           0.810539           0.797958   \n",
       "18           0.803002           0.802251           0.789210   \n",
       "19           0.794792           0.796034           0.775275   \n",
       "20           0.797280           0.801999           0.785495   \n",
       "21           0.789309           0.787293           0.773025   \n",
       "22           0.793888           0.794074           0.780819   \n",
       "23           0.785719           0.784360           0.770505   \n",
       "24           0.767802           0.769024           0.771289   \n",
       "25           0.779036           0.770820           0.768193   \n",
       "26           0.786136           0.775112           0.767849   \n",
       "27           0.773225           0.774547           0.773852   \n",
       "28           0.770983           0.774963           0.766821   \n",
       "29           0.774243           0.780715           0.762326   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.780846         0.783515        0.004680               23  \n",
       "1            0.835898         0.832955        0.006746               12  \n",
       "2            0.845059         0.841246        0.005288               10  \n",
       "3            0.856212         0.858267        0.004433                2  \n",
       "4            0.857753         0.856492        0.005487                4  \n",
       "5            0.858675         0.858428        0.005730                1  \n",
       "6            0.850808         0.845884        0.005388                8  \n",
       "7            0.849060         0.849596        0.004247                7  \n",
       "8            0.857843         0.858029        0.003746                3  \n",
       "9            0.847911         0.849804        0.004988                6  \n",
       "10           0.851158         0.853603        0.005518                5  \n",
       "11           0.840789         0.841923        0.006094                9  \n",
       "12           0.839887         0.839675        0.006486               11  \n",
       "13           0.822229         0.825507        0.007135               14  \n",
       "14           0.826022         0.830350        0.008086               13  \n",
       "15           0.811319         0.814254        0.007492               16  \n",
       "16           0.816674         0.820699        0.008541               15  \n",
       "17           0.804023         0.807693        0.005883               17  \n",
       "18           0.801388         0.800200        0.005635               18  \n",
       "19           0.790724         0.790824        0.008081               20  \n",
       "20           0.791953         0.795483        0.006083               19  \n",
       "21           0.781326         0.784386        0.006551               22  \n",
       "22           0.789515         0.790571        0.005204               21  \n",
       "23           0.779268         0.781159        0.005848               24  \n",
       "24           0.766956         0.771253        0.005181               29  \n",
       "25           0.767502         0.773694        0.006172               28  \n",
       "26           0.768363         0.775784        0.007181               25  \n",
       "27           0.763270         0.769511        0.005365               30  \n",
       "28           0.773811         0.773765        0.005087               27  \n",
       "29           0.776076         0.775726        0.007719               26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.97      0.97     20458\n",
      "        True       0.75      0.75      0.75      2715\n",
      "\n",
      "    accuracy                           0.94     23173\n",
      "   macro avg       0.86      0.86      0.86     23173\n",
      "weighted avg       0.94      0.94      0.94     23173\n",
      "\n",
      "[[19788   670]\n",
      " [  686  2029]]\n"
     ]
    }
   ],
   "source": [
    "display(pd.DataFrame(grid.cv_results_))\n",
    "Y_pred=grid.best_estimator_.predict(X_test)\n",
    "print((metrics.classification_report(Y_test,Y_pred)))\n",
    "print(metrics.confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "\n",
      "Best R^2 Score : 0.86  Best Params :  {'clf__C': 1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=comments['comment']\n",
    "Y=comments['attack']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=12)\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf',LogisticRegression())\n",
    "])\n",
    "#score,confusion=kCrossValidation(clf,comments)\n",
    "parameter={\n",
    "    'clf__class_weight':[{False:1,True:1},{False:1,True:2},{False:1,True:3},{False:1,True:4},{False:1,True:5},'balanced'],\n",
    "    #'clf__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'clf__C':[0.1, 1, 10, 100, 1000],\n",
    "    'clf__solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'clf__penalty':['l2'],\n",
    "}\n",
    "'''grid = GridSearchCV(clf,\n",
    "                    'clf__param_grid' :{#'max_depth': [None, 2,3,5], 'max_features' : ['auto','sqrt', 'log2'], 'n_estimators': [10,100],\n",
    "                                  'class_weight':[{False:1,True:1},{False:1,True:2},{False:1,True:5},'balanced',{False:1,True:10}]},\n",
    "                    #cv = ShuffleSplit(n_splits=5, random_state=123),\n",
    "                    'clf__scoring':'f1_macro',\n",
    "                    'clf__verbose':50,\n",
    "                    'clf__n_jobs':-1)\n",
    "'''\n",
    "grid=GridSearchCV(clf,param_grid=parameter,scoring='f1_macro',verbose=50,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "print('\\nBest R^2 Score : %.2f'%grid.best_score_, ' Best Params : ', str(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_clf__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.280313</td>\n",
       "      <td>0.325620</td>\n",
       "      <td>6.018108</td>\n",
       "      <td>0.155452</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.739417</td>\n",
       "      <td>0.734207</td>\n",
       "      <td>0.743120</td>\n",
       "      <td>0.733623</td>\n",
       "      <td>0.739199</td>\n",
       "      <td>0.737913</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.658701</td>\n",
       "      <td>0.379139</td>\n",
       "      <td>5.910600</td>\n",
       "      <td>0.134464</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.739417</td>\n",
       "      <td>0.734207</td>\n",
       "      <td>0.743120</td>\n",
       "      <td>0.733623</td>\n",
       "      <td>0.739199</td>\n",
       "      <td>0.737913</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.484431</td>\n",
       "      <td>0.221678</td>\n",
       "      <td>5.844778</td>\n",
       "      <td>0.071228</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.739941</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.743897</td>\n",
       "      <td>0.733359</td>\n",
       "      <td>0.739986</td>\n",
       "      <td>0.738331</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.943520</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>6.641768</td>\n",
       "      <td>0.460036</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.817947</td>\n",
       "      <td>0.816910</td>\n",
       "      <td>0.816476</td>\n",
       "      <td>0.801739</td>\n",
       "      <td>0.814554</td>\n",
       "      <td>0.813525</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.551775</td>\n",
       "      <td>0.902932</td>\n",
       "      <td>6.084838</td>\n",
       "      <td>0.053937</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.817947</td>\n",
       "      <td>0.816910</td>\n",
       "      <td>0.816476</td>\n",
       "      <td>0.801739</td>\n",
       "      <td>0.814554</td>\n",
       "      <td>0.813525</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41.673721</td>\n",
       "      <td>0.410922</td>\n",
       "      <td>6.422847</td>\n",
       "      <td>0.154121</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.817837</td>\n",
       "      <td>0.816819</td>\n",
       "      <td>0.816966</td>\n",
       "      <td>0.801943</td>\n",
       "      <td>0.815472</td>\n",
       "      <td>0.813808</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.324198</td>\n",
       "      <td>0.495759</td>\n",
       "      <td>6.025293</td>\n",
       "      <td>0.246093</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.839566</td>\n",
       "      <td>0.837772</td>\n",
       "      <td>0.835569</td>\n",
       "      <td>0.824229</td>\n",
       "      <td>0.834693</td>\n",
       "      <td>0.834366</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43.475924</td>\n",
       "      <td>0.410520</td>\n",
       "      <td>5.813060</td>\n",
       "      <td>0.071374</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.839566</td>\n",
       "      <td>0.837772</td>\n",
       "      <td>0.835569</td>\n",
       "      <td>0.824229</td>\n",
       "      <td>0.834693</td>\n",
       "      <td>0.834366</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42.448239</td>\n",
       "      <td>0.796913</td>\n",
       "      <td>6.080146</td>\n",
       "      <td>0.300719</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.839462</td>\n",
       "      <td>0.837842</td>\n",
       "      <td>0.835292</td>\n",
       "      <td>0.823926</td>\n",
       "      <td>0.834940</td>\n",
       "      <td>0.834293</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47.003636</td>\n",
       "      <td>0.638239</td>\n",
       "      <td>6.650617</td>\n",
       "      <td>0.496539</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.841549</td>\n",
       "      <td>0.834519</td>\n",
       "      <td>0.837618</td>\n",
       "      <td>0.824339</td>\n",
       "      <td>0.835603</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43.280552</td>\n",
       "      <td>1.040448</td>\n",
       "      <td>5.906410</td>\n",
       "      <td>0.138929</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.841549</td>\n",
       "      <td>0.834519</td>\n",
       "      <td>0.837714</td>\n",
       "      <td>0.824339</td>\n",
       "      <td>0.835603</td>\n",
       "      <td>0.834745</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41.685678</td>\n",
       "      <td>0.677076</td>\n",
       "      <td>5.978025</td>\n",
       "      <td>0.312985</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.837714</td>\n",
       "      <td>0.824339</td>\n",
       "      <td>0.835668</td>\n",
       "      <td>0.834848</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.599898</td>\n",
       "      <td>0.735036</td>\n",
       "      <td>6.100094</td>\n",
       "      <td>0.216488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.836406</td>\n",
       "      <td>0.832938</td>\n",
       "      <td>0.834050</td>\n",
       "      <td>0.819117</td>\n",
       "      <td>0.829567</td>\n",
       "      <td>0.830416</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40.885053</td>\n",
       "      <td>2.939467</td>\n",
       "      <td>5.394560</td>\n",
       "      <td>0.788367</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.836406</td>\n",
       "      <td>0.832938</td>\n",
       "      <td>0.834050</td>\n",
       "      <td>0.819117</td>\n",
       "      <td>0.829658</td>\n",
       "      <td>0.830434</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32.427876</td>\n",
       "      <td>2.364113</td>\n",
       "      <td>4.387599</td>\n",
       "      <td>0.090252</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.836223</td>\n",
       "      <td>0.832998</td>\n",
       "      <td>0.833960</td>\n",
       "      <td>0.818941</td>\n",
       "      <td>0.829567</td>\n",
       "      <td>0.830338</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.735584</td>\n",
       "      <td>0.562371</td>\n",
       "      <td>4.615856</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.801408</td>\n",
       "      <td>0.803518</td>\n",
       "      <td>0.800159</td>\n",
       "      <td>0.786405</td>\n",
       "      <td>0.800990</td>\n",
       "      <td>0.798496</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30.907679</td>\n",
       "      <td>0.149141</td>\n",
       "      <td>4.476127</td>\n",
       "      <td>0.134469</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.801408</td>\n",
       "      <td>0.803518</td>\n",
       "      <td>0.800082</td>\n",
       "      <td>0.786405</td>\n",
       "      <td>0.800990</td>\n",
       "      <td>0.798481</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30.560331</td>\n",
       "      <td>0.269101</td>\n",
       "      <td>4.410505</td>\n",
       "      <td>0.190985</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.801408</td>\n",
       "      <td>0.803518</td>\n",
       "      <td>0.799989</td>\n",
       "      <td>0.786680</td>\n",
       "      <td>0.801051</td>\n",
       "      <td>0.798529</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33.783261</td>\n",
       "      <td>0.198013</td>\n",
       "      <td>4.447907</td>\n",
       "      <td>0.301070</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.836947</td>\n",
       "      <td>0.836930</td>\n",
       "      <td>0.836541</td>\n",
       "      <td>0.820787</td>\n",
       "      <td>0.834295</td>\n",
       "      <td>0.833100</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32.810503</td>\n",
       "      <td>0.229190</td>\n",
       "      <td>4.419890</td>\n",
       "      <td>0.185989</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.836833</td>\n",
       "      <td>0.836930</td>\n",
       "      <td>0.836541</td>\n",
       "      <td>0.820787</td>\n",
       "      <td>0.834295</td>\n",
       "      <td>0.833077</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30.752444</td>\n",
       "      <td>0.330415</td>\n",
       "      <td>4.374099</td>\n",
       "      <td>0.253006</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.836947</td>\n",
       "      <td>0.836816</td>\n",
       "      <td>0.836541</td>\n",
       "      <td>0.820898</td>\n",
       "      <td>0.834492</td>\n",
       "      <td>0.833139</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.413802</td>\n",
       "      <td>0.933699</td>\n",
       "      <td>4.332271</td>\n",
       "      <td>0.195696</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>0.853904</td>\n",
       "      <td>0.858862</td>\n",
       "      <td>0.846479</td>\n",
       "      <td>0.854367</td>\n",
       "      <td>0.855076</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33.136162</td>\n",
       "      <td>0.545009</td>\n",
       "      <td>4.617262</td>\n",
       "      <td>0.274782</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>0.854075</td>\n",
       "      <td>0.859031</td>\n",
       "      <td>0.846479</td>\n",
       "      <td>0.854259</td>\n",
       "      <td>0.855123</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31.906308</td>\n",
       "      <td>0.624472</td>\n",
       "      <td>4.794378</td>\n",
       "      <td>0.467583</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>0.853904</td>\n",
       "      <td>0.859031</td>\n",
       "      <td>0.846585</td>\n",
       "      <td>0.854367</td>\n",
       "      <td>0.855131</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>35.742946</td>\n",
       "      <td>0.508740</td>\n",
       "      <td>4.561850</td>\n",
       "      <td>0.202901</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.859018</td>\n",
       "      <td>0.858907</td>\n",
       "      <td>0.861215</td>\n",
       "      <td>0.846570</td>\n",
       "      <td>0.855371</td>\n",
       "      <td>0.856216</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33.009976</td>\n",
       "      <td>0.549268</td>\n",
       "      <td>4.316782</td>\n",
       "      <td>0.082843</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.859018</td>\n",
       "      <td>0.859223</td>\n",
       "      <td>0.861318</td>\n",
       "      <td>0.846570</td>\n",
       "      <td>0.855209</td>\n",
       "      <td>0.856268</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31.299596</td>\n",
       "      <td>0.281169</td>\n",
       "      <td>4.662483</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.859018</td>\n",
       "      <td>0.858805</td>\n",
       "      <td>0.861215</td>\n",
       "      <td>0.846570</td>\n",
       "      <td>0.855371</td>\n",
       "      <td>0.856196</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34.531105</td>\n",
       "      <td>0.286099</td>\n",
       "      <td>4.509257</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.853724</td>\n",
       "      <td>0.856087</td>\n",
       "      <td>0.853177</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.850745</td>\n",
       "      <td>0.850898</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>34.075663</td>\n",
       "      <td>0.542089</td>\n",
       "      <td>4.564263</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.853766</td>\n",
       "      <td>0.856389</td>\n",
       "      <td>0.853482</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.850899</td>\n",
       "      <td>0.851059</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32.515375</td>\n",
       "      <td>0.234475</td>\n",
       "      <td>4.396945</td>\n",
       "      <td>0.237256</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.853528</td>\n",
       "      <td>0.856238</td>\n",
       "      <td>0.853177</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.850842</td>\n",
       "      <td>0.850909</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>35.318601</td>\n",
       "      <td>0.552513</td>\n",
       "      <td>4.642662</td>\n",
       "      <td>0.308719</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.849454</td>\n",
       "      <td>0.850855</td>\n",
       "      <td>0.846065</td>\n",
       "      <td>0.832150</td>\n",
       "      <td>0.844495</td>\n",
       "      <td>0.844604</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33.320931</td>\n",
       "      <td>0.795809</td>\n",
       "      <td>4.512682</td>\n",
       "      <td>0.382750</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.849454</td>\n",
       "      <td>0.850615</td>\n",
       "      <td>0.846065</td>\n",
       "      <td>0.832150</td>\n",
       "      <td>0.844495</td>\n",
       "      <td>0.844556</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31.788523</td>\n",
       "      <td>0.269053</td>\n",
       "      <td>4.420840</td>\n",
       "      <td>0.246004</td>\n",
       "      <td>1</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.849454</td>\n",
       "      <td>0.850762</td>\n",
       "      <td>0.846065</td>\n",
       "      <td>0.832150</td>\n",
       "      <td>0.844495</td>\n",
       "      <td>0.844585</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.631147</td>\n",
       "      <td>0.466487</td>\n",
       "      <td>4.440105</td>\n",
       "      <td>0.473089</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.827856</td>\n",
       "      <td>0.832009</td>\n",
       "      <td>0.827727</td>\n",
       "      <td>0.816409</td>\n",
       "      <td>0.828454</td>\n",
       "      <td>0.826491</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33.207827</td>\n",
       "      <td>0.631102</td>\n",
       "      <td>4.598362</td>\n",
       "      <td>0.317183</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.827941</td>\n",
       "      <td>0.832009</td>\n",
       "      <td>0.827643</td>\n",
       "      <td>0.816409</td>\n",
       "      <td>0.828454</td>\n",
       "      <td>0.826491</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>33.187401</td>\n",
       "      <td>0.559520</td>\n",
       "      <td>4.962070</td>\n",
       "      <td>0.637164</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.827941</td>\n",
       "      <td>0.832009</td>\n",
       "      <td>0.827560</td>\n",
       "      <td>0.816409</td>\n",
       "      <td>0.828539</td>\n",
       "      <td>0.826492</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36.262771</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>4.199957</td>\n",
       "      <td>0.191728</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.856119</td>\n",
       "      <td>0.853103</td>\n",
       "      <td>0.851170</td>\n",
       "      <td>0.840083</td>\n",
       "      <td>0.847506</td>\n",
       "      <td>0.849596</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>32.991401</td>\n",
       "      <td>0.256141</td>\n",
       "      <td>4.320396</td>\n",
       "      <td>0.233896</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.856099</td>\n",
       "      <td>0.852306</td>\n",
       "      <td>0.851676</td>\n",
       "      <td>0.839902</td>\n",
       "      <td>0.847426</td>\n",
       "      <td>0.849482</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>32.248914</td>\n",
       "      <td>0.654807</td>\n",
       "      <td>4.501267</td>\n",
       "      <td>0.233322</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.856119</td>\n",
       "      <td>0.853103</td>\n",
       "      <td>0.851347</td>\n",
       "      <td>0.840083</td>\n",
       "      <td>0.847436</td>\n",
       "      <td>0.849617</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>36.077175</td>\n",
       "      <td>0.553173</td>\n",
       "      <td>4.397068</td>\n",
       "      <td>0.204269</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.855856</td>\n",
       "      <td>0.853575</td>\n",
       "      <td>0.852262</td>\n",
       "      <td>0.841579</td>\n",
       "      <td>0.846219</td>\n",
       "      <td>0.849898</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>32.865554</td>\n",
       "      <td>0.255857</td>\n",
       "      <td>4.312346</td>\n",
       "      <td>0.224921</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.856794</td>\n",
       "      <td>0.853840</td>\n",
       "      <td>0.852571</td>\n",
       "      <td>0.840048</td>\n",
       "      <td>0.848719</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>32.382952</td>\n",
       "      <td>0.315533</td>\n",
       "      <td>4.376254</td>\n",
       "      <td>0.223886</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.855856</td>\n",
       "      <td>0.853575</td>\n",
       "      <td>0.852365</td>\n",
       "      <td>0.841579</td>\n",
       "      <td>0.846219</td>\n",
       "      <td>0.849919</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>36.937998</td>\n",
       "      <td>0.491282</td>\n",
       "      <td>4.490157</td>\n",
       "      <td>0.066736</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.850279</td>\n",
       "      <td>0.848071</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.840653</td>\n",
       "      <td>0.843789</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>33.951534</td>\n",
       "      <td>0.228478</td>\n",
       "      <td>4.341630</td>\n",
       "      <td>0.145448</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>0.850006</td>\n",
       "      <td>0.850261</td>\n",
       "      <td>0.833484</td>\n",
       "      <td>0.842001</td>\n",
       "      <td>0.844895</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>33.742931</td>\n",
       "      <td>0.684578</td>\n",
       "      <td>4.481843</td>\n",
       "      <td>0.216212</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.850279</td>\n",
       "      <td>0.847974</td>\n",
       "      <td>0.847879</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.840653</td>\n",
       "      <td>0.843769</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>37.608307</td>\n",
       "      <td>0.350494</td>\n",
       "      <td>4.446194</td>\n",
       "      <td>0.133074</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.841519</td>\n",
       "      <td>0.840407</td>\n",
       "      <td>0.842302</td>\n",
       "      <td>0.826773</td>\n",
       "      <td>0.835025</td>\n",
       "      <td>0.837205</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>33.048788</td>\n",
       "      <td>0.223764</td>\n",
       "      <td>4.417918</td>\n",
       "      <td>0.284368</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.842050</td>\n",
       "      <td>0.839378</td>\n",
       "      <td>0.842658</td>\n",
       "      <td>0.827325</td>\n",
       "      <td>0.835119</td>\n",
       "      <td>0.837306</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>33.030280</td>\n",
       "      <td>0.219027</td>\n",
       "      <td>4.358356</td>\n",
       "      <td>0.154326</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.841424</td>\n",
       "      <td>0.840407</td>\n",
       "      <td>0.842396</td>\n",
       "      <td>0.826773</td>\n",
       "      <td>0.835119</td>\n",
       "      <td>0.837224</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>38.426188</td>\n",
       "      <td>0.345083</td>\n",
       "      <td>4.499948</td>\n",
       "      <td>0.260998</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.834632</td>\n",
       "      <td>0.833385</td>\n",
       "      <td>0.836984</td>\n",
       "      <td>0.821319</td>\n",
       "      <td>0.830996</td>\n",
       "      <td>0.831463</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>34.543388</td>\n",
       "      <td>0.499542</td>\n",
       "      <td>4.422189</td>\n",
       "      <td>0.109306</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>0.834576</td>\n",
       "      <td>0.837282</td>\n",
       "      <td>0.820904</td>\n",
       "      <td>0.830691</td>\n",
       "      <td>0.831526</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>32.476301</td>\n",
       "      <td>0.391842</td>\n",
       "      <td>4.580691</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>10</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.834632</td>\n",
       "      <td>0.833622</td>\n",
       "      <td>0.836893</td>\n",
       "      <td>0.821319</td>\n",
       "      <td>0.830996</td>\n",
       "      <td>0.831492</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>35.542533</td>\n",
       "      <td>0.363839</td>\n",
       "      <td>4.453728</td>\n",
       "      <td>0.120231</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.827631</td>\n",
       "      <td>0.827809</td>\n",
       "      <td>0.828840</td>\n",
       "      <td>0.814498</td>\n",
       "      <td>0.826182</td>\n",
       "      <td>0.824992</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>34.421792</td>\n",
       "      <td>0.601573</td>\n",
       "      <td>4.696305</td>\n",
       "      <td>0.385114</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.827184</td>\n",
       "      <td>0.828839</td>\n",
       "      <td>0.813331</td>\n",
       "      <td>0.824867</td>\n",
       "      <td>0.823996</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>34.636986</td>\n",
       "      <td>0.451380</td>\n",
       "      <td>4.519256</td>\n",
       "      <td>0.291732</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.827544</td>\n",
       "      <td>0.827809</td>\n",
       "      <td>0.828754</td>\n",
       "      <td>0.814498</td>\n",
       "      <td>0.826182</td>\n",
       "      <td>0.824957</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>40.544040</td>\n",
       "      <td>0.789564</td>\n",
       "      <td>4.364706</td>\n",
       "      <td>0.305115</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.836266</td>\n",
       "      <td>0.829676</td>\n",
       "      <td>0.836155</td>\n",
       "      <td>0.814968</td>\n",
       "      <td>0.826104</td>\n",
       "      <td>0.828634</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>33.448924</td>\n",
       "      <td>0.540728</td>\n",
       "      <td>4.547691</td>\n",
       "      <td>0.279864</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.846943</td>\n",
       "      <td>0.840056</td>\n",
       "      <td>0.840870</td>\n",
       "      <td>0.826340</td>\n",
       "      <td>0.833666</td>\n",
       "      <td>0.837575</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>34.909200</td>\n",
       "      <td>0.375558</td>\n",
       "      <td>4.483325</td>\n",
       "      <td>0.205585</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.836266</td>\n",
       "      <td>0.829775</td>\n",
       "      <td>0.836256</td>\n",
       "      <td>0.814968</td>\n",
       "      <td>0.826203</td>\n",
       "      <td>0.828694</td>\n",
       "      <td>0.007878</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>42.014717</td>\n",
       "      <td>1.059749</td>\n",
       "      <td>4.601486</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.827373</td>\n",
       "      <td>0.824272</td>\n",
       "      <td>0.824536</td>\n",
       "      <td>0.808760</td>\n",
       "      <td>0.818033</td>\n",
       "      <td>0.820594</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>34.023530</td>\n",
       "      <td>0.401996</td>\n",
       "      <td>4.553809</td>\n",
       "      <td>0.315592</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.840050</td>\n",
       "      <td>0.834836</td>\n",
       "      <td>0.832086</td>\n",
       "      <td>0.826668</td>\n",
       "      <td>0.833392</td>\n",
       "      <td>0.833407</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>36.025013</td>\n",
       "      <td>0.656275</td>\n",
       "      <td>4.395989</td>\n",
       "      <td>0.143818</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.827629</td>\n",
       "      <td>0.824272</td>\n",
       "      <td>0.824536</td>\n",
       "      <td>0.808760</td>\n",
       "      <td>0.818033</td>\n",
       "      <td>0.820646</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>42.626906</td>\n",
       "      <td>0.440182</td>\n",
       "      <td>4.467908</td>\n",
       "      <td>0.169768</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.820737</td>\n",
       "      <td>0.819325</td>\n",
       "      <td>0.815664</td>\n",
       "      <td>0.803762</td>\n",
       "      <td>0.812300</td>\n",
       "      <td>0.814358</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>33.570878</td>\n",
       "      <td>0.574603</td>\n",
       "      <td>4.427088</td>\n",
       "      <td>0.248688</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.837279</td>\n",
       "      <td>0.828289</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.816132</td>\n",
       "      <td>0.823562</td>\n",
       "      <td>0.827287</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>37.867310</td>\n",
       "      <td>1.245295</td>\n",
       "      <td>4.500799</td>\n",
       "      <td>0.212169</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.820827</td>\n",
       "      <td>0.819325</td>\n",
       "      <td>0.815664</td>\n",
       "      <td>0.803920</td>\n",
       "      <td>0.812300</td>\n",
       "      <td>0.814408</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>43.882893</td>\n",
       "      <td>1.293512</td>\n",
       "      <td>4.379441</td>\n",
       "      <td>0.096762</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.816050</td>\n",
       "      <td>0.816031</td>\n",
       "      <td>0.812172</td>\n",
       "      <td>0.800056</td>\n",
       "      <td>0.807836</td>\n",
       "      <td>0.810429</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33.962274</td>\n",
       "      <td>0.541995</td>\n",
       "      <td>4.486884</td>\n",
       "      <td>0.258254</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.827962</td>\n",
       "      <td>0.824118</td>\n",
       "      <td>0.828327</td>\n",
       "      <td>0.803602</td>\n",
       "      <td>0.818488</td>\n",
       "      <td>0.820499</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>39.492405</td>\n",
       "      <td>3.542348</td>\n",
       "      <td>5.820868</td>\n",
       "      <td>1.345729</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.816050</td>\n",
       "      <td>0.816183</td>\n",
       "      <td>0.812172</td>\n",
       "      <td>0.800140</td>\n",
       "      <td>0.807924</td>\n",
       "      <td>0.810494</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>65.555577</td>\n",
       "      <td>2.967776</td>\n",
       "      <td>6.009536</td>\n",
       "      <td>0.606420</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.811496</td>\n",
       "      <td>0.812071</td>\n",
       "      <td>0.809303</td>\n",
       "      <td>0.796280</td>\n",
       "      <td>0.806102</td>\n",
       "      <td>0.807050</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>45.782213</td>\n",
       "      <td>0.746035</td>\n",
       "      <td>5.824428</td>\n",
       "      <td>0.406474</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.820870</td>\n",
       "      <td>0.814499</td>\n",
       "      <td>0.813211</td>\n",
       "      <td>0.803562</td>\n",
       "      <td>0.808089</td>\n",
       "      <td>0.812046</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>56.652031</td>\n",
       "      <td>3.403319</td>\n",
       "      <td>6.266457</td>\n",
       "      <td>0.515711</td>\n",
       "      <td>100</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.811582</td>\n",
       "      <td>0.812071</td>\n",
       "      <td>0.809388</td>\n",
       "      <td>0.796363</td>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.807084</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>58.770721</td>\n",
       "      <td>0.390445</td>\n",
       "      <td>5.911398</td>\n",
       "      <td>0.306115</td>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.808802</td>\n",
       "      <td>0.810873</td>\n",
       "      <td>0.809321</td>\n",
       "      <td>0.795402</td>\n",
       "      <td>0.808003</td>\n",
       "      <td>0.806480</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>46.962058</td>\n",
       "      <td>0.775472</td>\n",
       "      <td>5.964862</td>\n",
       "      <td>0.206537</td>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.816762</td>\n",
       "      <td>0.812749</td>\n",
       "      <td>0.812490</td>\n",
       "      <td>0.799822</td>\n",
       "      <td>0.815986</td>\n",
       "      <td>0.811562</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>52.558510</td>\n",
       "      <td>1.107918</td>\n",
       "      <td>5.843780</td>\n",
       "      <td>0.518512</td>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 100, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.809034</td>\n",
       "      <td>0.810873</td>\n",
       "      <td>0.809321</td>\n",
       "      <td>0.795402</td>\n",
       "      <td>0.808003</td>\n",
       "      <td>0.806527</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>74.863314</td>\n",
       "      <td>2.947360</td>\n",
       "      <td>6.498721</td>\n",
       "      <td>0.538695</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.801127</td>\n",
       "      <td>0.795686</td>\n",
       "      <td>0.800564</td>\n",
       "      <td>0.781132</td>\n",
       "      <td>0.792546</td>\n",
       "      <td>0.794211</td>\n",
       "      <td>0.007269</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>45.018435</td>\n",
       "      <td>3.919369</td>\n",
       "      <td>5.323437</td>\n",
       "      <td>0.763879</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.834806</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>0.832220</td>\n",
       "      <td>0.808066</td>\n",
       "      <td>0.828690</td>\n",
       "      <td>0.827358</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>43.570611</td>\n",
       "      <td>2.635235</td>\n",
       "      <td>4.422500</td>\n",
       "      <td>0.256658</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 1}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.801127</td>\n",
       "      <td>0.795607</td>\n",
       "      <td>0.800741</td>\n",
       "      <td>0.781048</td>\n",
       "      <td>0.792715</td>\n",
       "      <td>0.794248</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>54.260911</td>\n",
       "      <td>1.195556</td>\n",
       "      <td>4.492596</td>\n",
       "      <td>0.296649</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.794801</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.791845</td>\n",
       "      <td>0.776085</td>\n",
       "      <td>0.786989</td>\n",
       "      <td>0.788654</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>33.424986</td>\n",
       "      <td>0.563823</td>\n",
       "      <td>4.357824</td>\n",
       "      <td>0.258509</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.833237</td>\n",
       "      <td>0.828458</td>\n",
       "      <td>0.826763</td>\n",
       "      <td>0.814941</td>\n",
       "      <td>0.823227</td>\n",
       "      <td>0.825325</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>51.599793</td>\n",
       "      <td>5.973462</td>\n",
       "      <td>4.480201</td>\n",
       "      <td>0.179312</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 2}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.794716</td>\n",
       "      <td>0.793214</td>\n",
       "      <td>0.791761</td>\n",
       "      <td>0.781045</td>\n",
       "      <td>0.786736</td>\n",
       "      <td>0.789494</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>55.642978</td>\n",
       "      <td>0.851721</td>\n",
       "      <td>4.440072</td>\n",
       "      <td>0.315605</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.790765</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.789594</td>\n",
       "      <td>0.773379</td>\n",
       "      <td>0.784441</td>\n",
       "      <td>0.785576</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>34.030613</td>\n",
       "      <td>0.963047</td>\n",
       "      <td>4.422365</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.835815</td>\n",
       "      <td>0.827485</td>\n",
       "      <td>0.828126</td>\n",
       "      <td>0.815281</td>\n",
       "      <td>0.820883</td>\n",
       "      <td>0.825518</td>\n",
       "      <td>0.006971</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>46.881555</td>\n",
       "      <td>3.449622</td>\n",
       "      <td>4.893569</td>\n",
       "      <td>0.422696</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 3}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.791005</td>\n",
       "      <td>0.789536</td>\n",
       "      <td>0.789512</td>\n",
       "      <td>0.773063</td>\n",
       "      <td>0.784194</td>\n",
       "      <td>0.785462</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>61.640975</td>\n",
       "      <td>4.803990</td>\n",
       "      <td>4.717678</td>\n",
       "      <td>0.315066</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.787636</td>\n",
       "      <td>0.788776</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.772053</td>\n",
       "      <td>0.782896</td>\n",
       "      <td>0.783727</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>34.037293</td>\n",
       "      <td>0.209951</td>\n",
       "      <td>4.420838</td>\n",
       "      <td>0.205109</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.825025</td>\n",
       "      <td>0.821678</td>\n",
       "      <td>0.821723</td>\n",
       "      <td>0.806831</td>\n",
       "      <td>0.823652</td>\n",
       "      <td>0.819782</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>58.261414</td>\n",
       "      <td>7.454449</td>\n",
       "      <td>4.840538</td>\n",
       "      <td>0.418302</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 4}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.787872</td>\n",
       "      <td>0.788939</td>\n",
       "      <td>0.787113</td>\n",
       "      <td>0.771974</td>\n",
       "      <td>0.782655</td>\n",
       "      <td>0.783711</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>63.454305</td>\n",
       "      <td>2.510306</td>\n",
       "      <td>5.202821</td>\n",
       "      <td>0.749431</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.787803</td>\n",
       "      <td>0.786991</td>\n",
       "      <td>0.785377</td>\n",
       "      <td>0.771202</td>\n",
       "      <td>0.781641</td>\n",
       "      <td>0.782603</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>34.602570</td>\n",
       "      <td>1.085832</td>\n",
       "      <td>4.472523</td>\n",
       "      <td>0.295771</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.819068</td>\n",
       "      <td>0.814171</td>\n",
       "      <td>0.804756</td>\n",
       "      <td>0.788276</td>\n",
       "      <td>0.800110</td>\n",
       "      <td>0.805276</td>\n",
       "      <td>0.010819</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.699625</td>\n",
       "      <td>9.135908</td>\n",
       "      <td>5.072351</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>1000</td>\n",
       "      <td>{False: 1, True: 5}</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.787884</td>\n",
       "      <td>0.786991</td>\n",
       "      <td>0.785297</td>\n",
       "      <td>0.771358</td>\n",
       "      <td>0.781641</td>\n",
       "      <td>0.782634</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>56.243098</td>\n",
       "      <td>3.185449</td>\n",
       "      <td>4.680256</td>\n",
       "      <td>0.275159</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}</td>\n",
       "      <td>0.787106</td>\n",
       "      <td>0.788672</td>\n",
       "      <td>0.786953</td>\n",
       "      <td>0.773888</td>\n",
       "      <td>0.783572</td>\n",
       "      <td>0.784038</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>34.454628</td>\n",
       "      <td>1.042425</td>\n",
       "      <td>4.602850</td>\n",
       "      <td>0.363017</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.810070</td>\n",
       "      <td>0.808440</td>\n",
       "      <td>0.798746</td>\n",
       "      <td>0.810842</td>\n",
       "      <td>0.808286</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>47.633216</td>\n",
       "      <td>2.561635</td>\n",
       "      <td>4.458498</td>\n",
       "      <td>1.138053</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__C': 1000, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}</td>\n",
       "      <td>0.786955</td>\n",
       "      <td>0.788672</td>\n",
       "      <td>0.786802</td>\n",
       "      <td>0.773965</td>\n",
       "      <td>0.783492</td>\n",
       "      <td>0.783977</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
       "0       45.280313      0.325620         6.018108        0.155452          0.1   \n",
       "1       42.658701      0.379139         5.910600        0.134464          0.1   \n",
       "2       42.484431      0.221678         5.844778        0.071228          0.1   \n",
       "3       46.943520      0.882156         6.641768        0.460036          0.1   \n",
       "4       43.551775      0.902932         6.084838        0.053937          0.1   \n",
       "5       41.673721      0.410922         6.422847        0.154121          0.1   \n",
       "6       45.324198      0.495759         6.025293        0.246093          0.1   \n",
       "7       43.475924      0.410520         5.813060        0.071374          0.1   \n",
       "8       42.448239      0.796913         6.080146        0.300719          0.1   \n",
       "9       47.003636      0.638239         6.650617        0.496539          0.1   \n",
       "10      43.280552      1.040448         5.906410        0.138929          0.1   \n",
       "11      41.685678      0.677076         5.978025        0.312985          0.1   \n",
       "12      45.599898      0.735036         6.100094        0.216488          0.1   \n",
       "13      40.885053      2.939467         5.394560        0.788367          0.1   \n",
       "14      32.427876      2.364113         4.387599        0.090252          0.1   \n",
       "15      33.735584      0.562371         4.615856        0.259511          0.1   \n",
       "16      30.907679      0.149141         4.476127        0.134469          0.1   \n",
       "17      30.560331      0.269101         4.410505        0.190985          0.1   \n",
       "18      33.783261      0.198013         4.447907        0.301070            1   \n",
       "19      32.810503      0.229190         4.419890        0.185989            1   \n",
       "20      30.752444      0.330415         4.374099        0.253006            1   \n",
       "21      34.413802      0.933699         4.332271        0.195696            1   \n",
       "22      33.136162      0.545009         4.617262        0.274782            1   \n",
       "23      31.906308      0.624472         4.794378        0.467583            1   \n",
       "24      35.742946      0.508740         4.561850        0.202901            1   \n",
       "25      33.009976      0.549268         4.316782        0.082843            1   \n",
       "26      31.299596      0.281169         4.662483        0.067485            1   \n",
       "27      34.531105      0.286099         4.509257        0.195683            1   \n",
       "28      34.075663      0.542089         4.564263        0.190963            1   \n",
       "29      32.515375      0.234475         4.396945        0.237256            1   \n",
       "30      35.318601      0.552513         4.642662        0.308719            1   \n",
       "31      33.320931      0.795809         4.512682        0.382750            1   \n",
       "32      31.788523      0.269053         4.420840        0.246004            1   \n",
       "33      34.631147      0.466487         4.440105        0.473089            1   \n",
       "34      33.207827      0.631102         4.598362        0.317183            1   \n",
       "35      33.187401      0.559520         4.962070        0.637164            1   \n",
       "36      36.262771      0.808919         4.199957        0.191728           10   \n",
       "37      32.991401      0.256141         4.320396        0.233896           10   \n",
       "38      32.248914      0.654807         4.501267        0.233322           10   \n",
       "39      36.077175      0.553173         4.397068        0.204269           10   \n",
       "40      32.865554      0.255857         4.312346        0.224921           10   \n",
       "41      32.382952      0.315533         4.376254        0.223886           10   \n",
       "42      36.937998      0.491282         4.490157        0.066736           10   \n",
       "43      33.951534      0.228478         4.341630        0.145448           10   \n",
       "44      33.742931      0.684578         4.481843        0.216212           10   \n",
       "45      37.608307      0.350494         4.446194        0.133074           10   \n",
       "46      33.048788      0.223764         4.417918        0.284368           10   \n",
       "47      33.030280      0.219027         4.358356        0.154326           10   \n",
       "48      38.426188      0.345083         4.499948        0.260998           10   \n",
       "49      34.543388      0.499542         4.422189        0.109306           10   \n",
       "50      32.476301      0.391842         4.580691        0.269010           10   \n",
       "51      35.542533      0.363839         4.453728        0.120231           10   \n",
       "52      34.421792      0.601573         4.696305        0.385114           10   \n",
       "53      34.636986      0.451380         4.519256        0.291732           10   \n",
       "54      40.544040      0.789564         4.364706        0.305115          100   \n",
       "55      33.448924      0.540728         4.547691        0.279864          100   \n",
       "56      34.909200      0.375558         4.483325        0.205585          100   \n",
       "57      42.014717      1.059749         4.601486        0.239061          100   \n",
       "58      34.023530      0.401996         4.553809        0.315592          100   \n",
       "59      36.025013      0.656275         4.395989        0.143818          100   \n",
       "60      42.626906      0.440182         4.467908        0.169768          100   \n",
       "61      33.570878      0.574603         4.427088        0.248688          100   \n",
       "62      37.867310      1.245295         4.500799        0.212169          100   \n",
       "63      43.882893      1.293512         4.379441        0.096762          100   \n",
       "64      33.962274      0.541995         4.486884        0.258254          100   \n",
       "65      39.492405      3.542348         5.820868        1.345729          100   \n",
       "66      65.555577      2.967776         6.009536        0.606420          100   \n",
       "67      45.782213      0.746035         5.824428        0.406474          100   \n",
       "68      56.652031      3.403319         6.266457        0.515711          100   \n",
       "69      58.770721      0.390445         5.911398        0.306115          100   \n",
       "70      46.962058      0.775472         5.964862        0.206537          100   \n",
       "71      52.558510      1.107918         5.843780        0.518512          100   \n",
       "72      74.863314      2.947360         6.498721        0.538695         1000   \n",
       "73      45.018435      3.919369         5.323437        0.763879         1000   \n",
       "74      43.570611      2.635235         4.422500        0.256658         1000   \n",
       "75      54.260911      1.195556         4.492596        0.296649         1000   \n",
       "76      33.424986      0.563823         4.357824        0.258509         1000   \n",
       "77      51.599793      5.973462         4.480201        0.179312         1000   \n",
       "78      55.642978      0.851721         4.440072        0.315605         1000   \n",
       "79      34.030613      0.963047         4.422365        0.173844         1000   \n",
       "80      46.881555      3.449622         4.893569        0.422696         1000   \n",
       "81      61.640975      4.803990         4.717678        0.315066         1000   \n",
       "82      34.037293      0.209951         4.420838        0.205109         1000   \n",
       "83      58.261414      7.454449         4.840538        0.418302         1000   \n",
       "84      63.454305      2.510306         5.202821        0.749431         1000   \n",
       "85      34.602570      1.085832         4.472523        0.295771         1000   \n",
       "86      61.699625      9.135908         5.072351        0.579603         1000   \n",
       "87      56.243098      3.185449         4.680256        0.275159         1000   \n",
       "88      34.454628      1.042425         4.602850        0.363017         1000   \n",
       "89      47.633216      2.561635         4.458498        1.138053         1000   \n",
       "\n",
       "   param_clf__class_weight param_clf__penalty param_clf__solver  \\\n",
       "0      {False: 1, True: 1}                 l2         newton-cg   \n",
       "1      {False: 1, True: 1}                 l2             lbfgs   \n",
       "2      {False: 1, True: 1}                 l2         liblinear   \n",
       "3      {False: 1, True: 2}                 l2         newton-cg   \n",
       "4      {False: 1, True: 2}                 l2             lbfgs   \n",
       "5      {False: 1, True: 2}                 l2         liblinear   \n",
       "6      {False: 1, True: 3}                 l2         newton-cg   \n",
       "7      {False: 1, True: 3}                 l2             lbfgs   \n",
       "8      {False: 1, True: 3}                 l2         liblinear   \n",
       "9      {False: 1, True: 4}                 l2         newton-cg   \n",
       "10     {False: 1, True: 4}                 l2             lbfgs   \n",
       "11     {False: 1, True: 4}                 l2         liblinear   \n",
       "12     {False: 1, True: 5}                 l2         newton-cg   \n",
       "13     {False: 1, True: 5}                 l2             lbfgs   \n",
       "14     {False: 1, True: 5}                 l2         liblinear   \n",
       "15                balanced                 l2         newton-cg   \n",
       "16                balanced                 l2             lbfgs   \n",
       "17                balanced                 l2         liblinear   \n",
       "18     {False: 1, True: 1}                 l2         newton-cg   \n",
       "19     {False: 1, True: 1}                 l2             lbfgs   \n",
       "20     {False: 1, True: 1}                 l2         liblinear   \n",
       "21     {False: 1, True: 2}                 l2         newton-cg   \n",
       "22     {False: 1, True: 2}                 l2             lbfgs   \n",
       "23     {False: 1, True: 2}                 l2         liblinear   \n",
       "24     {False: 1, True: 3}                 l2         newton-cg   \n",
       "25     {False: 1, True: 3}                 l2             lbfgs   \n",
       "26     {False: 1, True: 3}                 l2         liblinear   \n",
       "27     {False: 1, True: 4}                 l2         newton-cg   \n",
       "28     {False: 1, True: 4}                 l2             lbfgs   \n",
       "29     {False: 1, True: 4}                 l2         liblinear   \n",
       "30     {False: 1, True: 5}                 l2         newton-cg   \n",
       "31     {False: 1, True: 5}                 l2             lbfgs   \n",
       "32     {False: 1, True: 5}                 l2         liblinear   \n",
       "33                balanced                 l2         newton-cg   \n",
       "34                balanced                 l2             lbfgs   \n",
       "35                balanced                 l2         liblinear   \n",
       "36     {False: 1, True: 1}                 l2         newton-cg   \n",
       "37     {False: 1, True: 1}                 l2             lbfgs   \n",
       "38     {False: 1, True: 1}                 l2         liblinear   \n",
       "39     {False: 1, True: 2}                 l2         newton-cg   \n",
       "40     {False: 1, True: 2}                 l2             lbfgs   \n",
       "41     {False: 1, True: 2}                 l2         liblinear   \n",
       "42     {False: 1, True: 3}                 l2         newton-cg   \n",
       "43     {False: 1, True: 3}                 l2             lbfgs   \n",
       "44     {False: 1, True: 3}                 l2         liblinear   \n",
       "45     {False: 1, True: 4}                 l2         newton-cg   \n",
       "46     {False: 1, True: 4}                 l2             lbfgs   \n",
       "47     {False: 1, True: 4}                 l2         liblinear   \n",
       "48     {False: 1, True: 5}                 l2         newton-cg   \n",
       "49     {False: 1, True: 5}                 l2             lbfgs   \n",
       "50     {False: 1, True: 5}                 l2         liblinear   \n",
       "51                balanced                 l2         newton-cg   \n",
       "52                balanced                 l2             lbfgs   \n",
       "53                balanced                 l2         liblinear   \n",
       "54     {False: 1, True: 1}                 l2         newton-cg   \n",
       "55     {False: 1, True: 1}                 l2             lbfgs   \n",
       "56     {False: 1, True: 1}                 l2         liblinear   \n",
       "57     {False: 1, True: 2}                 l2         newton-cg   \n",
       "58     {False: 1, True: 2}                 l2             lbfgs   \n",
       "59     {False: 1, True: 2}                 l2         liblinear   \n",
       "60     {False: 1, True: 3}                 l2         newton-cg   \n",
       "61     {False: 1, True: 3}                 l2             lbfgs   \n",
       "62     {False: 1, True: 3}                 l2         liblinear   \n",
       "63     {False: 1, True: 4}                 l2         newton-cg   \n",
       "64     {False: 1, True: 4}                 l2             lbfgs   \n",
       "65     {False: 1, True: 4}                 l2         liblinear   \n",
       "66     {False: 1, True: 5}                 l2         newton-cg   \n",
       "67     {False: 1, True: 5}                 l2             lbfgs   \n",
       "68     {False: 1, True: 5}                 l2         liblinear   \n",
       "69                balanced                 l2         newton-cg   \n",
       "70                balanced                 l2             lbfgs   \n",
       "71                balanced                 l2         liblinear   \n",
       "72     {False: 1, True: 1}                 l2         newton-cg   \n",
       "73     {False: 1, True: 1}                 l2             lbfgs   \n",
       "74     {False: 1, True: 1}                 l2         liblinear   \n",
       "75     {False: 1, True: 2}                 l2         newton-cg   \n",
       "76     {False: 1, True: 2}                 l2             lbfgs   \n",
       "77     {False: 1, True: 2}                 l2         liblinear   \n",
       "78     {False: 1, True: 3}                 l2         newton-cg   \n",
       "79     {False: 1, True: 3}                 l2             lbfgs   \n",
       "80     {False: 1, True: 3}                 l2         liblinear   \n",
       "81     {False: 1, True: 4}                 l2         newton-cg   \n",
       "82     {False: 1, True: 4}                 l2             lbfgs   \n",
       "83     {False: 1, True: 4}                 l2         liblinear   \n",
       "84     {False: 1, True: 5}                 l2         newton-cg   \n",
       "85     {False: 1, True: 5}                 l2             lbfgs   \n",
       "86     {False: 1, True: 5}                 l2         liblinear   \n",
       "87                balanced                 l2         newton-cg   \n",
       "88                balanced                 l2             lbfgs   \n",
       "89                balanced                 l2         liblinear   \n",
       "\n",
       "                                                                                                          params  \\\n",
       "0    {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "1        {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "2    {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "3    {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "4        {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "5    {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "6    {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "7        {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "8    {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "9    {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "10       {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "11   {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "12   {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "13       {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "14   {'clf__C': 0.1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "15            {'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "16                {'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "17            {'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "18     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "19         {'clf__C': 1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "20     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "21     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "22         {'clf__C': 1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "23     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "24     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "25         {'clf__C': 1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "26     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "27     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "28         {'clf__C': 1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "29     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "30     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "31         {'clf__C': 1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "32     {'clf__C': 1, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "33              {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "34                  {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "35              {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "36    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "37        {'clf__C': 10, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "38    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "39    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "40        {'clf__C': 10, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "41    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "42    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "43        {'clf__C': 10, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "44    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "45    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "46        {'clf__C': 10, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "47    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "48    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "49        {'clf__C': 10, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "50    {'clf__C': 10, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "51             {'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "52                 {'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "53             {'clf__C': 10, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "54   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "55       {'clf__C': 100, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "56   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "57   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "58       {'clf__C': 100, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "59   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "60   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "61       {'clf__C': 100, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "62   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "63   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "64       {'clf__C': 100, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "65   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "66   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "67       {'clf__C': 100, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "68   {'clf__C': 100, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "69            {'clf__C': 100, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "70                {'clf__C': 100, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "71            {'clf__C': 100, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "72  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "73      {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "74  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 1}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "75  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "76      {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "77  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 2}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "78  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "79      {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "80  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 3}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "81  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "82      {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "83  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 4}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "84  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "85      {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "86  {'clf__C': 1000, 'clf__class_weight': {False: 1, True: 5}, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "87           {'clf__C': 1000, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg'}   \n",
       "88               {'clf__C': 1000, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n",
       "89           {'clf__C': 1000, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.739417           0.734207           0.743120   \n",
       "1            0.739417           0.734207           0.743120   \n",
       "2            0.739941           0.734472           0.743897   \n",
       "3            0.817947           0.816910           0.816476   \n",
       "4            0.817947           0.816910           0.816476   \n",
       "5            0.817837           0.816819           0.816966   \n",
       "6            0.839566           0.837772           0.835569   \n",
       "7            0.839566           0.837772           0.835569   \n",
       "8            0.839462           0.837842           0.835292   \n",
       "9            0.841549           0.834519           0.837618   \n",
       "10           0.841549           0.834519           0.837714   \n",
       "11           0.841905           0.834615           0.837714   \n",
       "12           0.836406           0.832938           0.834050   \n",
       "13           0.836406           0.832938           0.834050   \n",
       "14           0.836223           0.832998           0.833960   \n",
       "15           0.801408           0.803518           0.800159   \n",
       "16           0.801408           0.803518           0.800082   \n",
       "17           0.801408           0.803518           0.799989   \n",
       "18           0.836947           0.836930           0.836541   \n",
       "19           0.836833           0.836930           0.836541   \n",
       "20           0.836947           0.836816           0.836541   \n",
       "21           0.861771           0.853904           0.858862   \n",
       "22           0.861771           0.854075           0.859031   \n",
       "23           0.861771           0.853904           0.859031   \n",
       "24           0.859018           0.858907           0.861215   \n",
       "25           0.859018           0.859223           0.861318   \n",
       "26           0.859018           0.858805           0.861215   \n",
       "27           0.853724           0.856087           0.853177   \n",
       "28           0.853766           0.856389           0.853482   \n",
       "29           0.853528           0.856238           0.853177   \n",
       "30           0.849454           0.850855           0.846065   \n",
       "31           0.849454           0.850615           0.846065   \n",
       "32           0.849454           0.850762           0.846065   \n",
       "33           0.827856           0.832009           0.827727   \n",
       "34           0.827941           0.832009           0.827643   \n",
       "35           0.827941           0.832009           0.827560   \n",
       "36           0.856119           0.853103           0.851170   \n",
       "37           0.856099           0.852306           0.851676   \n",
       "38           0.856119           0.853103           0.851347   \n",
       "39           0.855856           0.853575           0.852262   \n",
       "40           0.856794           0.853840           0.852571   \n",
       "41           0.855856           0.853575           0.852365   \n",
       "42           0.850279           0.848071           0.847879   \n",
       "43           0.848724           0.850006           0.850261   \n",
       "44           0.850279           0.847974           0.847879   \n",
       "45           0.841519           0.840407           0.842302   \n",
       "46           0.842050           0.839378           0.842658   \n",
       "47           0.841424           0.840407           0.842396   \n",
       "48           0.834632           0.833385           0.836984   \n",
       "49           0.834177           0.834576           0.837282   \n",
       "50           0.834632           0.833622           0.836893   \n",
       "51           0.827631           0.827809           0.828840   \n",
       "52           0.825758           0.827184           0.828839   \n",
       "53           0.827544           0.827809           0.828754   \n",
       "54           0.836266           0.829676           0.836155   \n",
       "55           0.846943           0.840056           0.840870   \n",
       "56           0.836266           0.829775           0.836256   \n",
       "57           0.827373           0.824272           0.824536   \n",
       "58           0.840050           0.834836           0.832086   \n",
       "59           0.827629           0.824272           0.824536   \n",
       "60           0.820737           0.819325           0.815664   \n",
       "61           0.837279           0.828289           0.831176   \n",
       "62           0.820827           0.819325           0.815664   \n",
       "63           0.816050           0.816031           0.812172   \n",
       "64           0.827962           0.824118           0.828327   \n",
       "65           0.816050           0.816183           0.812172   \n",
       "66           0.811496           0.812071           0.809303   \n",
       "67           0.820870           0.814499           0.813211   \n",
       "68           0.811582           0.812071           0.809388   \n",
       "69           0.808802           0.810873           0.809321   \n",
       "70           0.816762           0.812749           0.812490   \n",
       "71           0.809034           0.810873           0.809321   \n",
       "72           0.801127           0.795686           0.800564   \n",
       "73           0.834806           0.833008           0.832220   \n",
       "74           0.801127           0.795607           0.800741   \n",
       "75           0.794801           0.793551           0.791845   \n",
       "76           0.833237           0.828458           0.826763   \n",
       "77           0.794716           0.793214           0.791761   \n",
       "78           0.790765           0.789700           0.789594   \n",
       "79           0.835815           0.827485           0.828126   \n",
       "80           0.791005           0.789536           0.789512   \n",
       "81           0.787636           0.788776           0.787275   \n",
       "82           0.825025           0.821678           0.821723   \n",
       "83           0.787872           0.788939           0.787113   \n",
       "84           0.787803           0.786991           0.785377   \n",
       "85           0.819068           0.814171           0.804756   \n",
       "86           0.787884           0.786991           0.785297   \n",
       "87           0.787106           0.788672           0.786953   \n",
       "88           0.813333           0.810070           0.808440   \n",
       "89           0.786955           0.788672           0.786802   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.733623           0.739199         0.737913        0.003554   \n",
       "1            0.733623           0.739199         0.737913        0.003554   \n",
       "2            0.733359           0.739986         0.738331        0.003897   \n",
       "3            0.801739           0.814554         0.813525        0.005995   \n",
       "4            0.801739           0.814554         0.813525        0.005995   \n",
       "5            0.801943           0.815472         0.813808        0.005980   \n",
       "6            0.824229           0.834693         0.834366        0.005347   \n",
       "7            0.824229           0.834693         0.834366        0.005347   \n",
       "8            0.823926           0.834940         0.834293        0.005444   \n",
       "9            0.824339           0.835603         0.834726        0.005720   \n",
       "10           0.824339           0.835603         0.834745        0.005730   \n",
       "11           0.824339           0.835668         0.834848        0.005817   \n",
       "12           0.819117           0.829567         0.830416        0.006064   \n",
       "13           0.819117           0.829658         0.830434        0.006061   \n",
       "14           0.818941           0.829567         0.830338        0.006088   \n",
       "15           0.786405           0.800990         0.798496        0.006146   \n",
       "16           0.786405           0.800990         0.798481        0.006142   \n",
       "17           0.786680           0.801051         0.798529        0.006034   \n",
       "18           0.820787           0.834295         0.833100        0.006234   \n",
       "19           0.820787           0.834295         0.833077        0.006221   \n",
       "20           0.820898           0.834492         0.833139        0.006185   \n",
       "21           0.846479           0.854367         0.855076        0.005195   \n",
       "22           0.846479           0.854259         0.855123        0.005216   \n",
       "23           0.846585           0.854367         0.855131        0.005185   \n",
       "24           0.846570           0.855371         0.856216        0.005174   \n",
       "25           0.846570           0.855209         0.856268        0.005234   \n",
       "26           0.846570           0.855371         0.856196        0.005164   \n",
       "27           0.840757           0.850745         0.850898        0.005347   \n",
       "28           0.840757           0.850899         0.851059        0.005436   \n",
       "29           0.840757           0.850842         0.850909        0.005357   \n",
       "30           0.832150           0.844495         0.844604        0.006631   \n",
       "31           0.832150           0.844495         0.844556        0.006586   \n",
       "32           0.832150           0.844495         0.844585        0.006614   \n",
       "33           0.816409           0.828454         0.826491        0.005279   \n",
       "34           0.816409           0.828454         0.826491        0.005280   \n",
       "35           0.816409           0.828539         0.826492        0.005283   \n",
       "36           0.840083           0.847506         0.849596        0.005517   \n",
       "37           0.839902           0.847426         0.849482        0.005524   \n",
       "38           0.840083           0.847436         0.849617        0.005533   \n",
       "39           0.841579           0.846219         0.849898        0.005241   \n",
       "40           0.840048           0.848719         0.850394        0.005786   \n",
       "41           0.841579           0.846219         0.849919        0.005251   \n",
       "42           0.832061           0.840653         0.843789        0.006702   \n",
       "43           0.833484           0.842001         0.844895        0.006452   \n",
       "44           0.832061           0.840653         0.843769        0.006689   \n",
       "45           0.826773           0.835025         0.837205        0.005804   \n",
       "46           0.827325           0.835119         0.837306        0.005654   \n",
       "47           0.826773           0.835119         0.837224        0.005800   \n",
       "48           0.821319           0.830996         0.831463        0.005428   \n",
       "49           0.820904           0.830691         0.831526        0.005709   \n",
       "50           0.821319           0.830996         0.831492        0.005428   \n",
       "51           0.814498           0.826182         0.824992        0.005315   \n",
       "52           0.813331           0.824867         0.823996        0.005499   \n",
       "53           0.814498           0.826182         0.824957        0.005294   \n",
       "54           0.814968           0.826104         0.828634        0.007862   \n",
       "55           0.826340           0.833666         0.837575        0.007018   \n",
       "56           0.814968           0.826203         0.828694        0.007878   \n",
       "57           0.808760           0.818033         0.820594        0.006658   \n",
       "58           0.826668           0.833392         0.833407        0.004320   \n",
       "59           0.808760           0.818033         0.820646        0.006711   \n",
       "60           0.803762           0.812300         0.814358        0.006059   \n",
       "61           0.816132           0.823562         0.827287        0.007131   \n",
       "62           0.803920           0.812300         0.814408        0.006023   \n",
       "63           0.800056           0.807836         0.810429        0.006006   \n",
       "64           0.803602           0.818488         0.820499        0.009161   \n",
       "65           0.800140           0.807924         0.810494        0.005998   \n",
       "66           0.796280           0.806102         0.807050        0.005778   \n",
       "67           0.803562           0.808089         0.812046        0.005880   \n",
       "68           0.796363           0.806016         0.807084        0.005770   \n",
       "69           0.795402           0.808003         0.806480        0.005618   \n",
       "70           0.799822           0.815986         0.811562        0.006111   \n",
       "71           0.795402           0.808003         0.806527        0.005638   \n",
       "72           0.781132           0.792546         0.794211        0.007269   \n",
       "73           0.808066           0.828690         0.827358        0.009849   \n",
       "74           0.781048           0.792715         0.794248        0.007320   \n",
       "75           0.776085           0.786989         0.788654        0.006822   \n",
       "76           0.814941           0.823227         0.825325        0.006111   \n",
       "77           0.781045           0.786736         0.789494        0.005005   \n",
       "78           0.773379           0.784441         0.785576        0.006483   \n",
       "79           0.815281           0.820883         0.825518        0.006971   \n",
       "80           0.773063           0.784194         0.785462        0.006619   \n",
       "81           0.772053           0.782896         0.783727        0.006170   \n",
       "82           0.806831           0.823652         0.819782        0.006596   \n",
       "83           0.771974           0.782655         0.783711        0.006246   \n",
       "84           0.771202           0.781641         0.782603        0.006081   \n",
       "85           0.788276           0.800110         0.805276        0.010819   \n",
       "86           0.771358           0.781641         0.782634        0.006030   \n",
       "87           0.773888           0.783572         0.784038        0.005341   \n",
       "88           0.798746           0.810842         0.808286        0.005024   \n",
       "89           0.773965           0.783492         0.783977        0.005279   \n",
       "\n",
       "    rank_test_score  \n",
       "0                89  \n",
       "1                89  \n",
       "2                88  \n",
       "3                61  \n",
       "4                61  \n",
       "5                60  \n",
       "6                29  \n",
       "7                29  \n",
       "8                31  \n",
       "9                28  \n",
       "10               27  \n",
       "11               26  \n",
       "12               40  \n",
       "13               39  \n",
       "14               41  \n",
       "15               74  \n",
       "16               75  \n",
       "17               73  \n",
       "18               34  \n",
       "19               35  \n",
       "20               33  \n",
       "21                6  \n",
       "22                5  \n",
       "23                4  \n",
       "24                2  \n",
       "25                1  \n",
       "26                3  \n",
       "27                9  \n",
       "28                7  \n",
       "29                8  \n",
       "30               17  \n",
       "31               19  \n",
       "32               18  \n",
       "33               48  \n",
       "34               47  \n",
       "35               46  \n",
       "36               14  \n",
       "37               15  \n",
       "38               13  \n",
       "39               12  \n",
       "40               10  \n",
       "41               11  \n",
       "42               20  \n",
       "43               16  \n",
       "44               21  \n",
       "45               25  \n",
       "46               23  \n",
       "47               24  \n",
       "48               38  \n",
       "49               36  \n",
       "50               37  \n",
       "51               51  \n",
       "52               53  \n",
       "53               52  \n",
       "54               43  \n",
       "55               22  \n",
       "56               42  \n",
       "57               55  \n",
       "58               32  \n",
       "59               54  \n",
       "60               59  \n",
       "61               45  \n",
       "62               58  \n",
       "63               66  \n",
       "64               56  \n",
       "65               65  \n",
       "66               69  \n",
       "67               63  \n",
       "68               68  \n",
       "69               71  \n",
       "70               64  \n",
       "71               70  \n",
       "72               77  \n",
       "73               44  \n",
       "74               76  \n",
       "75               79  \n",
       "76               50  \n",
       "77               78  \n",
       "78               80  \n",
       "79               49  \n",
       "80               81  \n",
       "81               84  \n",
       "82               57  \n",
       "83               85  \n",
       "84               87  \n",
       "85               72  \n",
       "86               86  \n",
       "87               82  \n",
       "88               67  \n",
       "89               83  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.97      0.97     20458\n",
      "        True       0.74      0.75      0.75      2715\n",
      "\n",
      "    accuracy                           0.94     23173\n",
      "   macro avg       0.86      0.86      0.86     23173\n",
      "weighted avg       0.94      0.94      0.94     23173\n",
      "\n",
      "[[19760   698]\n",
      " [  683  2032]]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(pd.DataFrame(grid.cv_results_))\n",
    "Y_pred=grid.best_estimator_.predict(X_test)\n",
    "print((metrics.classification_report(Y_test,Y_pred)))\n",
    "print(metrics.confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prevalence of personal attacks by namespace\n",
    "In this section we use our classifier in conjunction with the [Wikipedia Talk Corpus](https://figshare.com/articles/Wikipedia_Talk_Corpus/4264973) to see if personal attacks are more common on user talk or article talk page discussions. In our paper we show that the model is not biased by namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-8f8535d6cbfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbernoulli\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2065\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2067\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2068\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-108>\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   2928\u001b[0m                 \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2930\u001b[1;33m         \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2931\u001b[0m         \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigure_inline_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mactivate_matplotlib\u001b[1;34m(backend)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'backend'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m \u001b[0m_backend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_figure_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_show\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[0m_IP_REGISTERED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\__init__.py\u001b[0m in \u001b[0;36mpylab_setup\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# imports. 0 means only perform absolute imports.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     backend_mod = __import__(backend_name,\n\u001b[1;32m---> 32\u001b[1;33m                              globals(),locals(),[backend_name],0)\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Things we pull in from all backends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_qt5agg.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackend_agg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackend_qt5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQtCore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackend_qt5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQtGui\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackend_qt5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFigureManagerQT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_qt5.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSubplotTool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqt_editor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigureoptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfigureoptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m from .qt_compat import (QtCore, QtGui, QtWidgets, _getSaveFileName,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\qt_editor\\figureoptions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqt_editor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformlayout\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mformlayout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqt_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQtGui\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\qt_editor\\formlayout.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqt_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQtGui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQtWidgets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQtCore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\qt_compat.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mQT_API\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mQT_API_PYQT5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[0mPyQt5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQtCore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQtGui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQtWidgets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             \u001b[0m_getSaveFileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQtWidgets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQFileDialog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetSaveFileName\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from scipy.stats import bernoulli\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download and untar data\n",
    "\n",
    "USER_TALK_CORPUS_2004_URL = 'https://ndownloader.figshare.com/files/6982061'\n",
    "ARTICLE_TALK_CORPUS_2004_URL = 'https://ndownloader.figshare.com/files/7038050'\n",
    "\n",
    "download_file(USER_TALK_CORPUS_2004_URL, 'comments_user_2004.tar.gz')\n",
    "download_file(ARTICLE_TALK_CORPUS_2004_URL,  'comments_article_2004.tar.gz')\n",
    "\n",
    "os.system('tar -xzf comments_user_2004.tar.gz')\n",
    "os.system('tar -xzf comments_article_2004.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper for collecting a sample of comments for a given ns and year from \n",
    "def load_no_bot_no_admin(ns, year, prob = 0.1):\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    data_dir = \"comments_%s_%d\" % (ns, year)\n",
    "    for _, _, filenames in os.walk(data_dir):\n",
    "        for filename in filenames:\n",
    "            if re.match(\"chunk_\\d*.tsv\", filename):\n",
    "                df = pd.read_csv(os.path.join(data_dir, filename), sep = \"\\t\")\n",
    "                df['include'] = bernoulli.rvs(prob, size=df.shape[0])\n",
    "                df = df.query(\"bot == 0 and admin == 0 and include == 1\")\n",
    "                dfs.append(df)\n",
    "                \n",
    "    sample = pd.concat(dfs)\n",
    "    sample['ns'] = ns\n",
    "    sample['year'] = year\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect a random sample of comments from 2004 for each namespace\n",
    "corpus_user = load_no_bot_no_admin('user', 2004)\n",
    "corpus_article = load_no_bot_no_admin('article', 2004)\n",
    "corpus = pd.concat([corpus_user, corpus_article])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply model\n",
    "corpus['comment'] = corpus['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "corpus['comment'] = corpus['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "corpus['attack'] = clf.predict_proba(corpus['comment'])[:,1] > 0.425 # see paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot prevalence per ns\n",
    "\n",
    "sns.pointplot(data = corpus, x = 'ns', y = 'attack')\n",
    "plt.ylabel(\"Attack fraction\")\n",
    "plt.xlabel(\"Dicussion namespace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attacks are far more prevalent in the user talk namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>this is not creative those are the dictionary ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less npov th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>true or false the situation as of march was su...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>next maybe you could work on being less condes...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>this page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699848324</th>\n",
       "      <td>these sources dont exactly exude a sense of im...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699851288</th>\n",
       "      <td>the institute for historical review is a peerr...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699857133</th>\n",
       "      <td>the way youre trying to describe it in this ar...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699891012</th>\n",
       "      <td>warning there is clearly a protectionist regim...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699897151</th>\n",
       "      <td>alternate option is there perhaps enough newsw...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     comment  year  logged_in  \\\n",
       "rev_id                                                                          \n",
       "37675      this is not creative those are the dictionary ...  2002      False   \n",
       "44816      the term standard model is itself less npov th...  2002      False   \n",
       "49851      true or false the situation as of march was su...  2002      False   \n",
       "89320      next maybe you could work on being less condes...  2002       True   \n",
       "93890                     this page will need disambiguation  2002       True   \n",
       "...                                                      ...   ...        ...   \n",
       "699848324  these sources dont exactly exude a sense of im...  2016       True   \n",
       "699851288  the institute for historical review is a peerr...  2016       True   \n",
       "699857133  the way youre trying to describe it in this ar...  2016       True   \n",
       "699891012  warning there is clearly a protectionist regim...  2016       True   \n",
       "699897151  alternate option is there perhaps enough newsw...  2016       True   \n",
       "\n",
       "                ns   sample  split  attack  \n",
       "rev_id                                      \n",
       "37675      article   random  train   False  \n",
       "44816      article   random  train   False  \n",
       "49851      article   random  train   False  \n",
       "89320      article   random    dev   False  \n",
       "93890      article   random  train   False  \n",
       "...            ...      ...    ...     ...  \n",
       "699848324  article  blocked  train   False  \n",
       "699851288  article  blocked   test   False  \n",
       "699857133  article  blocked  train   False  \n",
       "699891012     user  blocked    dev   False  \n",
       "699897151  article  blocked  train   False  \n",
       "\n",
       "[115864 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
